{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "y02c_toxic_dl_distilbertfast_pytorch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LoD-DWn6HpZg"
      },
      "source": [
        "# Description\n",
        "In this project, we use the data from kaggle competition [Toxic Comment Classification Challenge by Jigsaw](https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/data?select=train.csv.zip) and only use the training data. Then we have break this raw training data into train and test data and evaluate the model performances in test data.\n",
        "\n",
        "The dataset is taken from wikipedia edit text and is classified as one of the following:\n",
        "\n",
        "1. toxic\n",
        "2. severe_toxic\n",
        "3. obscene\n",
        "4. threat\n",
        "5. insult\n",
        "6. identity_hate\n",
        "\n",
        "This is a multi-label (not-multiclass) classification. One text row has six labels and exactly one label is 1 and other labels are 0.\n",
        "\n",
        "\n",
        "References:\n",
        "- [Hugging face pretrained model names](https://huggingface.co/transformers/pretrained_models.html#pretrained-models)\n",
        "- [transformers example](https://colab.research.google.com/github/rap12391/transformers_multilabel_toxic/blob/master/toxic_multilabel.ipynb)\n",
        "- [Kaggle: Fastai with Transformers (BERT, RoBERTa)](https://www.kaggle.com/maroberti/fastai-with-transformers-bert-roberta)\n",
        "\n",
        "\n",
        "# Deep Learning NLP\n",
        "Transformers Models\n",
        "- BERT (from Google)\n",
        "- XLNet (from Google/CMU)\n",
        "- XLM (from Facebook)\n",
        "- RoBERTa (from Facebook)\n",
        "- DistilBERT (from Hugging Face)\n",
        "\n",
        "Notes:\n",
        "1. As we are not using RNN, we have to limit the sequence length to the model input size.\n",
        "1. Most of the models require special tokens placed at the beginning and end of the sequences.\n",
        "1. Some models like RoBERTa require a space to start the input string. For those models, the encoding methods should be called with add_prefix_space set to True.\n",
        "\n",
        "\n",
        "```\n",
        "\n",
        "bert:       [CLS] + tokens + [SEP] + padding\n",
        "\n",
        "roberta:    [CLS] + prefix_space + tokens + [SEP] + padding\n",
        "\n",
        "distilbert: [CLS] + tokens + [SEP] + padding\n",
        "\n",
        "xlm:        [CLS] + tokens + [SEP] + padding\n",
        "\n",
        "xlnet:      padding + tokens + [SEP] + [CLS]\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MxgsdVubH8_M"
      },
      "source": [
        "# Load the Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MW5YkqIc2R3n"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import time\n",
        "\n",
        "time_start_notebook = time.time()"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zmnOPZa-2T6R"
      },
      "source": [
        "%%capture\n",
        "import os\n",
        "import sys\n",
        "ENV_COLAB = 'google.colab' in sys.modules\n",
        "\n",
        "if ENV_COLAB:\n",
        "    ## install modules\n",
        "    !pip install sentencepiece # xlnet needs this\n",
        "    !pip install transformers\n",
        "    !pip install scikit-plot\n",
        "    !pip install watermark"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93PsJlWZ2WLX",
        "outputId": "b84e78e0-7399-4e77-9306-19c415e1d562"
      },
      "source": [
        "# data science\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "# visualization\n",
        "import seaborn as sns\n",
        "sns.set(color_codes=True)\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# mixed\n",
        "import os\n",
        "import time\n",
        "from pprint import pprint\n",
        "import joblib\n",
        "import pickle\n",
        "from tqdm import tqdm, trange\n",
        "from ast import literal_eval\n",
        "\n",
        "# random state\n",
        "SEED=100\n",
        "np.random.seed(SEED)\n",
        "\n",
        "# machine learning\n",
        "import sklearn\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix, multilabel_confusion_matrix\n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "\n",
        "# deep learning\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "import torch\n",
        "from torch.nn import BCEWithLogitsLoss, BCELoss\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from torch.utils.data import RandomSampler, SequentialSampler\n",
        "import transformers\n",
        "from transformers import *\n",
        "\n",
        "# model eval\n",
        "import scikitplot as skplt\n",
        "\n",
        "# versions\n",
        "import watermark\n",
        "%load_ext watermark\n",
        "%watermark -a \"Bhishan Poudel\" -d -v -m\n",
        "print()\n",
        "%watermark -iv"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Bhishan Poudel 2020-12-06 \n",
            "\n",
            "CPython 3.6.9\n",
            "IPython 5.5.0\n",
            "\n",
            "compiler   : GCC 8.4.0\n",
            "system     : Linux\n",
            "release    : 4.19.112+\n",
            "machine    : x86_64\n",
            "processor  : x86_64\n",
            "CPU cores  : 4\n",
            "interpreter: 64bit\n",
            "\n",
            "torch                   1.7.0+cu101\n",
            "numpy                   1.18.5\n",
            "transformers            4.0.0\n",
            "seaborn                 0.11.0\n",
            "matplotlib              3.2.2\n",
            "sklearn                 0.22.2.post1\n",
            "scikitplot              0.3.7\n",
            "watermark               2.0.2\n",
            "tensorflow              2.3.0\n",
            "joblib                  0.17.0\n",
            "pandas                  1.1.4\n",
            "transformers.file_utils 4.0.0\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JedTdTP82YoF"
      },
      "source": [
        "# Useful Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prsDn_X72bWe"
      },
      "source": [
        "def show_methods(obj, ncols=4,contains=None):\n",
        "    lst = [i for i in dir(obj) if i[0]!='_' ]\n",
        "    if contains is not None:\n",
        "        lst = [i for i in lst if contains in i]\n",
        "    df = pd.DataFrame(np.array_split(lst,ncols)).T.fillna('')\n",
        "    return df"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bgM_SMST2b05"
      },
      "source": [
        "def seed_all(seed):\n",
        "    import random\n",
        "    random.seed(seed) # Python\n",
        "    np.random.seed(seed) # cpu vars\n",
        "    torch.manual_seed(seed) # cpu  vars\n",
        "    \n",
        "    if torch.cuda.is_available(): \n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed) # gpu vars\n",
        "        torch.backends.cudnn.deterministic = True  #needed\n",
        "        torch.backends.cudnn.benchmark = False"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCsjt4vj2b3s"
      },
      "source": [
        "seed_all(seed=SEED)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5D7al0Ar2iVm"
      },
      "source": [
        "# GPU Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cv23KKPQ2ky2",
        "outputId": "1fc16539-b109-473f-bc7d-f1f04e79f77f"
      },
      "source": [
        "# We must use gpu for this notebook, it is needed later\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "RYLBguWH2nGZ",
        "outputId": "ae5aced0-861f-4166-f705-00c9fa2d80a6"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "n_gpu = torch.cuda.device_count()\n",
        "torch.cuda.get_device_name(0)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Tesla P100-PCIE-16GB'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F3fR_MIW2b6M"
      },
      "source": [
        "## Load Training Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eis83ViP2b9T"
      },
      "source": [
        "# %%capture\n",
        "\n",
        "# # Once you downloaded the data, comment this cell\n",
        "# download_data = True\n",
        "# if download_data:\n",
        "#     !wget https://github.com/bhishanpdl/Datasets/blob/master/Projects/Jigsaw_Toxic_Comment_Classification/train.csv.zip?raw=true\n",
        "#     !unzip train.csv.zip?raw=true\n",
        "\n",
        "#     !wget https://github.com/bhishanpdl/Datasets/blob/master/Projects/Jigsaw_Toxic_Comment_Classification/test.csv.zip?raw=true\n",
        "#     !unzip test.csv.zip?raw=true"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yKHt2Ypg2cAI",
        "outputId": "997a4dbe-78f6-4491-cfbf-562fda7ae5bb"
      },
      "source": [
        "os.listdir()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['.config',\n",
              " 'train.csv',\n",
              " 'test.csv.zip?raw=true',\n",
              " 'train.csv.zip?raw=true.1',\n",
              " 'test.csv',\n",
              " 'test.csv.zip?raw=true.1',\n",
              " 'train.csv.zip?raw=true',\n",
              " 'sample_data']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "BIRxXxNZ2cCT",
        "outputId": "d13d8772-747b-4771-b31c-6505e8022d11"
      },
      "source": [
        "df_train = pd.read_csv('train.csv')\n",
        "df_train.head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>comment_text</th>\n",
              "      <th>toxic</th>\n",
              "      <th>severe_toxic</th>\n",
              "      <th>obscene</th>\n",
              "      <th>threat</th>\n",
              "      <th>insult</th>\n",
              "      <th>identity_hate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>8d603d50affa1126</td>\n",
              "      <td>\"\\nYes, aside, thank you for trying to answer ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>8fb3576937b9e0d0</td>\n",
              "      <td>March 2010 (UTC)\\n\\nThanks! and understood abo...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>379440e04fb68e27</td>\n",
              "      <td>\"\\n\\n The Outfield \\n\\nHahaha - compassion is ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6be4446aac8ae028</td>\n",
              "      <td>Opposition is a source of strength. I believe ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1a2ff7ed958506a3</td>\n",
              "      <td>Please discontinue making those unsupported ch...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 id  ... identity_hate\n",
              "0  8d603d50affa1126  ...             0\n",
              "1  8fb3576937b9e0d0  ...             0\n",
              "2  379440e04fb68e27  ...             0\n",
              "3  6be4446aac8ae028  ...             0\n",
              "4  1a2ff7ed958506a3  ...             0\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oLHIbGUC2cFv",
        "outputId": "ff5e7194-27d9-4a2c-d900-ac91d29679f8"
      },
      "source": [
        "col_text = 'comment_text'\n",
        "\n",
        "# unique text\n",
        "print('unique text')\n",
        "print(df_train[col_text].nunique(), df_train.shape[0])\n",
        "\n",
        "# null values\n",
        "print('nan text')\n",
        "df_train.isnull().sum()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "unique text\n",
            "127656 127656\n",
            "nan text\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id               0\n",
              "comment_text     0\n",
              "toxic            0\n",
              "severe_toxic     0\n",
              "obscene          0\n",
              "threat           0\n",
              "insult           0\n",
              "identity_hate    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFt_04Jf2cG-"
      },
      "source": [
        "cols_label = ['toxic', 'severe_toxic', 'obscene',\n",
        "              'threat', 'insult', 'identity_hate']"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gYMqGbWx2cJl",
        "outputId": "96a5f6a5-8c8b-403b-fd41-67098c0359bd"
      },
      "source": [
        "print('Count of 1 per label: \\n', df_train[cols_label].sum(), '\\n') \n",
        "print('Count of 0 per label: \\n', df_train[cols_label].eq(0).sum())"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Count of 1 per label: \n",
            " toxic            12202\n",
            "severe_toxic      1282\n",
            "obscene           6782\n",
            "threat             379\n",
            "insult            6292\n",
            "identity_hate     1136\n",
            "dtype: int64 \n",
            "\n",
            "Count of 0 per label: \n",
            " toxic            115454\n",
            "severe_toxic     126374\n",
            "obscene          120874\n",
            "threat           127277\n",
            "insult           121364\n",
            "identity_hate    126520\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "id": "SnuYwjex2px9",
        "outputId": "5116c95a-f1cf-436b-c558-5e3ccda2ec96"
      },
      "source": [
        "df_train[cols_label].sum().plot.bar(title='Count of 1s',color='tomato');"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAFKCAYAAADooaOnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de5hkVX3u8W/3jAzgjKM07QUUUWReDI5ywGsEEnLiJTkxagzEUUBEUYx3xbtHIaJBYoxBRplETVAIKh4FjYGgnhgEvKCCih5eEBHxgjQNAoMywHSfP/ZupqaZNdNdVV27qvr9PE8/PbVXVddvd/XUW3uvtdcamZ6eJiIiYktGmy4gIiL6V0IiIiKKEhIREVGUkIiIiKKEREREFCUkIiKiaGnTBUTE1kl6NnAScD/gANuXNFxSLCIJiVg0JD0PeB2wF3ArcCnwbtsXLPDzTgN72v5xmz/ifcArbJ9d+PnvAp4FPBI43vaxbT5PxD3kdFMsCpJeB3wAeA/wAGA34EPAM5usa44eCvxwK+0/Bt4IfLE35cRiMpIrrmPYSVoJ/AJ4oe0zC/dZBrwXOKTe9GngTbY3SDoCeLHt/Vvuf/fRgaR/BW4DdgcOBH4EPM/2VZLOBw4AfgtMAy+y/alZzz0KvBU4CtgBOBd4JXA7MAncu378dbb32Mp+ngb8uPVIQtIjgI8C+wB3Al+x/Vdb+31FtMqRRCwGTwK2Bz63lfu8DXgi1ZvpY4DHA2+fx3M8FziOqt/gx8C7AWwfWLc/xvby2QFRO6L+Ogh4OLAcONn2BtvLWx5fDIiteBdwXl3Xg4EPtvEzYhFLSMRiMAbcYPuurdzn+cDf2L7e9gTVG/5h83iOz9n+Vv0cp1OFzVw9H3i/7Z/YXg+8BXiupG70Gd5JdbpqF9u3L3T/SwyfhEQsBpPAztt4090FuKbl9jX1trm6ruXfv6U6GpirLT33Uqq+k069ERgBviXph5KO7MLPjEUkIRGLwdeBDVQjgEp+SfWJe8Zu9Tao+ht2nGmQ9MAu17el574L+HWnP9j2dbaPsr0L8FLgQ3U/RcScZAhsDD3bN0t6B7BW0l1U5+jvBP4YOMj2G4EzgLdLupiqg/kdwGn1j/gesLekfYDLgWPnWcKvqfoaSkNgzwDeJOkcYIJqBNantnF67G6S7gUsofrQt1TS9sCdtjdKOhj4uu2fAzfV+zY1z/pjEcuRRCwKtv+e6hqJt1O9EV8LvAI4q77L8cC3ge8DPwC+W2/D9hXA3wBfBq4E5nte/1jgVEm/kXTIFto/BnwCOB+4mmpU0yvn8fP/GfgdsIaqA/53bOpPeRzwTUnrgc8Dr7b9k3nWH4tYhsBGRERRjiQiIqIoIREREUUJiYiIKEpIRERE0bANgV1GNZrjV8DGhmuJiBgUS4AHARdTXVN0t2ELiccBX2u6iIiIAXUAs4Z4D1tI/ArgpptuY2qqN0N7x8aWMzm5vifP1WvDvG+Q/Rt02b/uGR0d4X73uzfU76Gthi0kNgJMTU33LCRmnm9YDfO+QfZv0GX/uu4ep+nTcR0REUUJiYiIKEpIREREUUIiIiKKEhIREVGUkIiIiKKEREREFM3pOglJ7wOeA+wOrLZ9maQxqoVS9gDuoFqM5aX1IvJIeiKwDtgB+ClwqO3rO2lbSGP32Y7RZcvaeuz4+Ip5P2ZqwwYmb7mjreeLiOiVuV5Mdxbwj2w+5cU0cKLtrwJI+jvgBOBFkkapln48wvYFkt5etx3ZblunO7oto8uWwYufvtBPs+n5PnIuVbZGRPSvOZ1usn2B7WtnbbtxJiBq32DTYu77AbfbnpkD5BTgkA7bIiKix7rSJ1EfAbyMag1dgN2Aa2babd8AjEraqYO2iIjosW7N3fRBYD1wcpd+XkfGxpY3XcKctNOX0WuDUGMnsn+DLfu38DoOibpTe0/gGban6s0/Y9OpJyTtDEzZvlFSW23zqWlycv28J8Zq4sWYmLi15885H+PjK/q+xk5k/wZb9q97RkdHih+uOzrdJOk9VP0Iz7LdulDFd4AdJO1f3z4aOLPDtoiI6LG5DoE9CfgL4IHAlyVNUnUovwW4ArhIEsDVtp9te0rSYcA6SdtTD2UFaLctIiJ6b04hYftVwKu20DSylcdcBKzuZltERPRWrriOiIiihERERBQlJCIioighERERRQmJiIgoSkhERERRQiIiIooSEhERUZSQiIiIooREREQUJSQiIqIoIREREUUJiYiIKEpIREREUUIiIiKKEhIREVGUkIiIiKKEREREFCUkIiKiKCERERFFCYmIiChKSERERFFCIiIiihISERFRlJCIiIiipdu6g6T3Ac8BdgdW276s3r4KOBUYAyaBw21fuVBtERHRe3M5kjgLOBC4Ztb2U4C1tlcBa4F1C9wWERE9ts0jCdsXAEi6e5uk+wP7Ak+pN50BnCxpHBjpdpvtiXZ3MCIi2tdun8RDgF/Y3ghQf/9lvX0h2iIiogHbPJIYRGNjy5suYU7Gx1c0XcI2DUKNncj+Dbbs38JrNySuBXaVtMT2RklLgF3q7SML0DYvk5PrmZqantdjmngxJiZu7flzzsf4+Iq+r7ET2b/Blv3rntHRkeKH67ZON9m+HrgUWFNvWgNcYntiIdraqTEiIjo3lyGwJwF/ATwQ+LKkSdt7A0cDp0p6B3ATcHjLwxaiLSIiemwuo5teBbxqC9svB55QeEzX2yIiovdyxXVERBQlJCIioighERERRQmJiIgoSkhERERRQiIiIooSEhERUZSQiIiIooREREQUJSQiIqIoIREREUUJiYiIKEpIREREUUIiIiKKEhIREVGUkIiIiKKEREREFCUkIiKiKCERERFFCYmIiChKSERERFFCIiIiihISERFRlJCIiIiihERERBQt7fQHSPoz4F3ASP11nO3PSloFnAqMAZPA4bavrB/TVltERPRWR0cSkkaATwCH2d4HOAw4VdIocAqw1vYqYC2wruWh7bZFREQPdXwkAUwBK+t/3xf4FbAzsC/wlHr7GcDJksapjjbm3WZ7ogu1RkTEPHR0JGF7GjgEOFvSNcBZwOHAQ4Bf2N5Y328j8Mt6e7ttERHRYx0dSUhaCrwFeKbtCyU9Gfg01WmnxoyNLW/y6edsfHxF0yVs0yDU2Ins32DL/i28Tk837QPsYvtCgDoobgNuB3aVtMT2RklLgF2Aa6lOKbXTNmeTk+uZmpqe14408WJMTNza8+ecj/HxFX1fYyeyf4Mt+9c9o6MjxQ/XnQ6B/TnwYEkCkPRI4AHAlcClwJr6fmuAS2xP2L6+nbYO64yIiDZ02idxHfAy4DOSvgd8EjjS9o3A0cArJV0BvLK+PaPdtoiI6KGORzfZPh04fQvbLweeUHhMW20REdFbueI6IiKKEhIREVGUkIiIiKKEREREFCUkIiKiKCERERFFCYmIiChKSERERFFCIiIiihISERFRlJCIiIiihERERBQlJCIioighERERRQmJiIgo6ng9iYimjd1nO0aXLWvrse0sWzu1YQOTt9zR1vNFDJqERAy80WXL4MVP793zfeRcICERi0NON0VERFFCIiIiihISERFRlJCIiIiihERERBQlJCIioighERERRblOIiIalYsh+1vHISFpe+AfgD8Gbge+bvslklYBpwJjwCRwuO0r68e01RYRwycXQ/a3bpxuOpEqHFbZXg3873r7KcBa26uAtcC6lse02xYRET3U0ZGEpOXA4cCDbU8D2P61pPsD+wJPqe96BnCypHFgpJ022xOd1BoREfPX6ZHEHlSnhN4p6duSvippf+AhwC9sbwSov/+y3t5uW0RE9FinfRJLgIcDl9h+g6QnAF8ADu64sg6MjS1v8unnrJ1Ot14bhBqbMCi/l0Gps9cG5ffSD3V2GhI/A+6iOi2E7W9KugH4HbCrpCW2N0paAuwCXEt1SqmdtjmbnFzP1NT0vHakiRdjYuLWnj/nfIyPr+j7GiGvXUlev7JB+b30qs7R0ZHih+uOTjfZvgH4L+o+hHpk0v2BK4BLgTX1XddQHW1M2L6+nbZO6oyIiPZ04zqJo4GPSfp74E7gMNu/kXQ0cKqkdwA3UXVwtz6mnbaIiOihjkPC9k+AP9zC9suBJxQe01ZbRET0VqbliIiIooREREQUJSQiIqIoIREREUUJiYiIKEpIREREUUIiIiKKEhIREVGUkIiIiKKEREREFCUkIiKiKCERERFFCYmIiChKSERERFFCIiIiihISERFRlJCIiIiihERERBQlJCIioighERERRQmJiIgoSkhERERRQiIiIooSEhERUZSQiIiIoqXd+kGS3gkcC6y2fZmkJwLrgB2AnwKH2r6+vm9bbRER0VtdOZKQtC/wROCa+vYocBrwcturgPOBEzppi4iI3us4JCQtA9YCL2vZvB9wu+0L6tunAId02BYRET3WjSOJvwFOs/3Tlm27UR9VANi+ARiVtFMHbRER0WMd9UlIehLwWODN3SmnO8bGljddwpyMj69ouoRtGoQamzAov5dBqbPXBuX30g91dtpx/QfAI4GrJQE8GPhP4CTgoTN3krQzMGX7Rkk/a6dtPkVNTq5namp6XjvSxIsxMXFrz59zPsbHV/R9jZDXriSvX9mg/F56Vefo6Ejxw3VHp5tsn2B7F9u7294d+DnwNODvgB0k7V/f9WjgzPrf32mzLSIiemxBrpOwPQUcBnxY0pVURxxv7qQtIiJ6r2vXSQDURxMz/74IWF24X1ttERHRW7niOiIiihISERFRlJCIiIiihERERBQlJCIioighERERRQmJiIgoSkhERERRQiIiIooSEhERUZSQiIiIooREREQUJSQiIqIoIREREUUJiYiIKEpIREREUUIiIiKKEhIREVGUkIiIiKKEREREFCUkIiKiKCERERFFCYmIiChKSERERFFCIiIiipZ28mBJY8AngD2AO4ArgZfanpD0RGAdsAPwU+BQ29fXj2urLSIieqvTI4lp4ETbsr0auAo4QdIocBrwcturgPOBEwDabYuIiN7rKCRs32j7qy2bvgE8FNgPuN32BfX2U4BD6n+32xYRET3W0emmVvVRwMuAzwO7AdfMtNm+QdKopJ3abbN941xrGRtb3vkO9cD4+IqmS9imQaixCYPyexmUOnttUH4v/VBn10IC+CCwHjgZeHYXf+68TU6uZ2pqel6PaeLFmJi4tefPOR/j4yv6vkbIa1eS169sUH4vvapzdHSk+OG6K6ObJL0P2BP4K9tTwM+oTjvNtO8MTNVHA+22RUREj3UcEpLeQ9WX8CzbG+rN3wF2kLR/ffto4MwO2yIiosc6HQK7N/AW4ArgIkkAV9t+tqTDgHWStqceygpge6qdtoiI6L2OQsL2D4GRQttFwOputkVERG/liuuIiChKSERERFFCIiIiihISERFRlJCIiIiihERERBQlJCIioqibczdFnxq7z3aMLlvW1mPbmVdnasMGJm+5o63ni4j+kpBYBEaXLYMXP713z/eRc6nWoIqIQZeQiIhYQIN+JJ+QiIhYQIN+JJ+O64iIKEpIREREUUIiIiKKEhIREVGUkIiIiKKEREREFCUkIiKiKCERERFFCYmIiChKSERERFFCIiIiijJ3U0SfG/QJ4mKwJSQi+tygTxAXgy2nmyIioqgvjyQkrQJOBcaASeBw21c2W1VExOLTr0cSpwBrba8C1gLrGq4nImJR6rsjCUn3B/YFnlJvOgM4WdK47YltPHwJwOjoSHtPPvaA9h7XprbrbMcw7xtk/7os+9dlfb5/LfdfMrttZHp6ugsldY+k/YCP2967ZduPgENtf3cbD98f+NpC1hcRMcQOAC5o3dB3RxIduphqJ38FbGy4loiIQbEEeBDVe+hm+jEkrgV2lbTE9kZJS4Bd6u3bsoFZKRgREXNy1ZY29l3Hte3rgUuBNfWmNcAlc+iPiIiILuu7PgkASXtRDYG9H3AT1RBYN1tVRMTi05chERER/aHvTjdFRET/SEhERERRQiIiIooSEhERUZSQiIiIooREREQUJSRiM5IOk3S/lts7SXp+kzXF3Eg6dC7bBpmke8yosKVtg0zSfSTt23QdMxIS8yTpJEk7tdwek/SBJmvqsmNs3zRzw/aNwDEN1tNVknaUdLykf6tv7yXpWU3X1SWvm+O2QbZj6w1Jo8BOhfsOHEl/CvwQ+Gx9+7GSvtBkTf04d1O/O6B+4wTA9qSkP2iyoB64x/TBA+zDVBNAPqa+/XOq6ejPaqyiDkl6LPAEYGdJf93StBLYrpmqukvSG4A3AislXd/StCNwejNVLYjjgMcB5wDY/rakPZosKEcS87elN8x79byKhXOdpL+YuSHpOcD1W7n/oHm07TdTL+Jsez2D//9gV+CxwL2p3mBmvh4IHNFcWV31T1T7dB6b7+NDbL+0ycK6zfZ1szZtaKSQWo4k5u9iSf8InAiMAG9gC9PrDrBXA2dLOrG+fRfwzAbr6bbN/sNJ2p4BDwnbZ1O9Zk+1fV7T9SwE2zcDNwN/1nQtC+xWSQ8ApgEk/SHwmyYLSkjM32uBDwCXUL2Q/w68ptGKusj25ZJ+D9CmTR6mtTnOl/RWYFn9H/B1wNnNltQdts+TJKpTadu3bP94c1V1h6SLqd84t8T243tYzkJ6C9WppodJ+iqwJ/DnTRaUCf4CAEnLbG+QtOOW2m3/ttc1LQRJ96I6t/3nVEeCnwdOsH1Xo4V1gaRXAS9l0+IxBwD/bftPGi2sC7bV72f7v3tVy0KTtBL4faq/z4ts50hiEEh6su0L69EH92D7P3pdU5d9nWpt8fVs/oltpL49FJ3Xtu8E3l1/DZuXAI8HLrT9NEmPAt7RcE1dMUwhsDWSPmD7NdQd17O2NSIhMXdHABdS9UHMNg0MdEjY3rf+PtDn57el7oN4PrAHLX//tt/YWFHdc7vt2ySNShqxfZmkVU0X1U2l005DdLrpwC1sa3T0ZEJijmwfVX8/qOlaFpKkR9v+/qxtT7P9n03V1GVnUg0L/SYNjxpZAL+tT6d9D3ivpGsZkiPAFq3X7GxPtXLlLxuqpWskHQwcAuwu6dMtTSuBRk/1JiTmSdJLbP9Ty+1R4Hjbb22wrG46S9J7ba+r9+3dwDOAYQmJR9h+ZNNFLJC/pgrA1wPvAR4OHNZoRV02+7STpPMYjnXtrwC+SHW68Ist228BvtJIRbWExPwdLOmPgBdTpfwngZ80W1JXPQk4TdL/pBpnfxXVH+6w+ImkFbZvbbqQbrN9Wf3P26j+PheD+1D9nQ40298Dvifp860X6/aDhMT8PRV4O/Adqk9tx9o+tdmSusf2ryWdDJxGNS79hcMysql2M/BtSf8J3D6zcRj6JCTtCfwLsKvth9Xz//y57WObrax7ZvVJjFIdLf19cxV13S2SXgLsw+bDmI9sqqCExPyNUh1B3EX1Iv6u2XK6S9L7gT+iuoJ3b+Arkt5k+1PNVtY1rr+G0YeB44ET6tuXAp8Ajm2qoAXQ2idxF/AT279qqpgFsI7qffkgqtfzecD5TRaUkJi/C4EfAPtRjUf/pKQ/sn10s2V1zQrgibZvByzpEqpTakMREraPa7qGBbTS9rmS/hbA9pSkO5ouqpta+yQk3Z/qSGKYQuLxtldL+r7tv5X0IRq+2DMhMX8ftD0zodjVkg4A3ttkQd1k+yhJSyXtPbMJ2L/JmrqpfmN5P7Cb7QMlPRr4fdunNFxaN2ysRzfNTOmwKzDVbEndJelrVFNzjFDNevAbSf9he0tD0wfRzJmJjZJ2tH1z/TfbmKEeE78QbJ8u6fckvVzSy4GH235t03V1i6T9qDqrP0c1M+qVwOpGi+quf6YaDXPf+vblVKOChsGHqF63nSUdC3wNeF+jFXXf8noepz+jmv11NfD0Zkvqqhvr9VzOBc6R9H+AXzRZUEJiniQdBnyJqmNpH+DLQ7Yoz0nAkbZX2d4TeBHwwYZr6qZd66OGjQC272BIPm3XczSdQDX1+Y7AC2yf0WxVXbes/n4Q8CXbU1R9E8Pif9XrubwN+AjwX8Bzmiwop5vm7xhgv5npfCU9kOoagmGZ0/7etu8el237/9ad2cNiszcUSfelOnUx0CQtAS6ur5wfhusGSr4q6UdU711H16/f0ExAOTOZZh1+n2i4HCBHEm1pne99C3O/D7rf1rOjAndPrDZMQ2A/K2kdsELSEVTrE3ys2ZI6V7+5rK+nHRlmL6ca8fPYeh6upcBRzZbUPZJ+X9IFkn4p6fqZryZrypHE/F0l6TiqoWpQ/YEO08V0rwY+I2lmyortgL9ssJ6usn1ifXrwvsCfAifZPq3hsrrFVFOhf4ZqosZqo/2h5krqLtvTkq4AHizpwfXmYZpe5aPAu4Bv0CdHSAmJ+Tua6rz996lGkXyZavbNoWD7YkmPYPP1JO5ssqZuq0enDcvpwVZLqdZHbp12ZKjWAqgHi5wA3MimvqRpqqGww+B3tv+t6SJaJSTm79yZGVNnSPou1TTbA0/Sp20fAly2hW0Drx4tctTM1AeSxoAPD8P+2X5h0zX0wOuBR9m+pulCFsh/SPoT2+ds+669kZCYI0lLqU69jEragU3rLNyXaiTJsHjEFrbt1fMqFs7DW+fGsT1ZHzkNhXrOrdnToA/N6SbgumEMCEkTVO8nI8BbJd1KdRptBJi23di1EgmJuXsb8E6qF/K2lu23MARzx0g6iuq02SpJ32ppWslwTWOxVNKSmVEk9cVny7bxmIEg6VSqmQC+y6bz2UN1ugn4Ur3++ifZfO6tHzVXUlc8tukCShISc1RP53CcpJNtv6LpehbAeVQXzp3M5gsr3ULV/zIszgU+JekD9e3X1NuGwZOAvYetD2mWw+vvB7dsG/g+ibkeHUn6Vq8XWEpIzNOQBsTMH+k1wKO2dj9JZ9l+Vm+qWhBvrb9mrv34dzZNiDform26gIVm+2FN19Cwe/X6CRMSMV8PbbqATtSfso+rv4aCpJlpRa6gmrX3LDY/FTPwfRKSltneIGmL/X9DNp391vT89GFCIuZroM9xS3od8NF64rSPUy2o9Crb5zVcWiceV39fSTXvVutcWyup5nQadF+nGkG4nk0dvDOmGb5lWvtGQiIWmyNsv1/SQcADgCOprnsZ2JCYGfoq6buF4dkDb2a/bC/2WSJ6PoVMQiIWm5lRPwcBp9u+qF7Le2AVhmdDdRQxTMOzo7oSu6cG+j9HNGLQO0d/J+lNwBrgPEkjVG+wg+xtVKdhHk01PHt9/fX/GM4ry4eWpMslvULSii21235Zr2samZ4e6FPM0WX1m+aRwCrbb5K0O7CL7Yuaraw7JK2iWj/ifNuflbQHcIjtv224tI4N8fDsRUPS/6CaxPAZwGeBtbYv2/qjFlZCIjYj6R+oztXva3uvetqKc3o9NnuhSVoOYHv9tu4b0Wv1FOhHAq8FrgY+YPuzTdSS000x20HA86mXUbQ9CQzN9NOS9pJ0MXADMCHpW5K0rcdF9NgTgD+kmqb/XKq1MxpZZz4hEbPdbvvuw8u6U3fgF+Vp8a9UK+3tQNWpexJwapMFRcyQdIykK6mOINYBe9l+j+2nUk250nMZ3RSz/aBeb2Gk7o94C9VaycNieb3M54zT6o7siH6wO/AM25dvoe2velwLkCOJuKfXUR3mPgj4JtXfyBu29oAB8x1J+8/ckPRk4NsN1hPR6mezA0LSGwFsf6eJgnIkEXer10k+xvZRDNGSkAB1P8Q01XDX8+tDeqimRh+mCQxjsD0XOHEO23omIRF3s71R0p9QTYk+bI6ZdXsFVWhkdFM0TtJTgKcCu9RToc9YScN9ggmJmO2Lko4BPs7m6yQP9ARqtv8boL4u4nRgH6qQuAQ4tMHSIgDuYNO8VK3r1fwKaPQanlwnEZuRNNVyc2YitWnbQzGBmqQvAWcA/1JvOgJ4nu2nNFZURE3So5q+eG62hEQsKpIutb3PtrZF9JKkg22f2TLt+2aanO49o5viHiStkvTM+t/LJe3UdE1dNNV68Vw9TcfGrdw/ohdmFvt63Ba+Gl3aNH0SsRlJRwBvphoFdDawK7AW+OMGy+qmtwJfk3RpffsxwGEN1hOB7ZnBIq+2fUtrm6T7NFDS3XIkEbO9muqTy80Atg08sNGKusj2ucDeVFdan0S1JvTAriURQ+erc9zWMzmSiNnusL1+1nRGdzVVzEKwPUG1tnVEX+jnNUFyJBGzTdbn6acBJB0K/LzZkiKG3syaIKvpszVBMropNlMHxL8BjwQmqGahfIbtqxotLGIR6Mc1QRIScQ/19ByrqA55bTujfyJ6SNJ2tHQHNHkxa/okYjOSPgp8zPaFTdcSsdhIejbVVPa70HIxK9DYxawJiZjtu8A/SlpJtfbCqbbTJxHRG38HHAJ8w/bUtu7cCzndFFskaTXwAqoZKH9o+2kNlxQx9CR9q9+WCs6RRJT8kGp89iOo1peIiIX3OUkvAz4F3D6zMX0S0TfqI4gjgDXAZVSnnNY0WFLEYvLu+vta+qRPIqebYjOSrqAKhk/YvrbhciKiYQmJiIg+Ul+r9EjbZ0taDmxn+8am6skV17EZSXtKukDS1fXtfSUd23BZEYtCPcHm54F/qDftCny6sYJISMQ9fRg4nnqCP+BS4ODmyolYVPpugs2ERMy2sp4pdRqgHqt9R7MlRSwad9ieve56oxNsJiRito2S7sWmCf52Bfriop6IRaDvJtjMENiY7UPA54Cd676IF1At1BMRC+81VBNsStJPqSfYbLKgjG6Ke5C0P5v+ML9g+4Im64lYTPptgs2ERGxG0ieBl1L1Q3wP2Bl4j+33NVpYxBCT9Htba7f9o17VMltON8Vssn2zpL8EvgK8HvgGkJCIWDhfZNMV1rsBt9S37wtcAzysqcLScR2z3av+/gfAOfWcMem4jlhAth9m++FUy+o+1/b9bO9ENSPsF5qsLSERs/1I0jlUfRJfqdfbjYjeOND2mTM3bH8GOLDBehIScQ8vANYBB9m+DdgJeHOzJUUsGiOSDpi5IenJNPw+nY7riIg+UQfEGcBt9aYdgDVNrhSZkIiI6CP1+taqb9p2ozMe5HRTRETDJC2rv+9INer0qj0U/5QAAAA+SURBVPprab2tMRkCGxHRvK8D+wLrqafkqGXRoYiI6F853RQREUUJiYiIKEpIREREUUIiIiKKEhIREVH0/wGoz8NpB3O1jgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "id": "fdfWr89j3OXQ",
        "outputId": "8f0bdc86-1131-4e5a-d954-b02d362db9d4"
      },
      "source": [
        "df_train[cols_label].eq(0).sum().plot.bar(title='Count of 0s');"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1bYHAtp3Oar"
      },
      "source": [
        "# Data Processing: Training Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oj_ul6303OeE"
      },
      "source": [
        "## Shuffle and create ohe column"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0TQjkykA3Ohd"
      },
      "source": [
        "# shuffle data\n",
        "df_train = df_train.sample(frac=1,random_state=SEED).reset_index(drop=True)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "id": "NlEa0zDN3Oi8",
        "outputId": "88e2a565-77f4-428c-a98c-63e2d9e31417"
      },
      "source": [
        "col_ohe = 'one_hot_labels'\n",
        "df_train[col_ohe] = df_train[cols_label].to_numpy().tolist()\n",
        "df_train.head(2)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>comment_text</th>\n",
              "      <th>toxic</th>\n",
              "      <th>severe_toxic</th>\n",
              "      <th>obscene</th>\n",
              "      <th>threat</th>\n",
              "      <th>insult</th>\n",
              "      <th>identity_hate</th>\n",
              "      <th>one_hot_labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>815dac68f62b1e6a</td>\n",
              "      <td>\"\\n\\n Defenestration \\n\\nIt was previously rep...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>570a66d523877761</td>\n",
              "      <td>I am easily able to trace my lineage back to C...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 id  ...      one_hot_labels\n",
              "0  815dac68f62b1e6a  ...  [0, 0, 0, 0, 0, 0]\n",
              "1  570a66d523877761  ...  [0, 0, 0, 0, 0, 0]\n",
              "\n",
              "[2 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LDnTP84w3Ol3"
      },
      "source": [
        "labels    = list(df_train[col_ohe].values)\n",
        "list_text = list(df_train[col_text].values)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BNvrq9OV3Oo-"
      },
      "source": [
        "# Choose Transformers Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nucQeofG3Ori",
        "outputId": "80906226-d7c5-4218-8851-cbfcd2842910"
      },
      "source": [
        "model_name = 'distilbertfast'\n",
        "num_labels = len(cols_label) # NUM_CLASSES\n",
        "\n",
        "#=======================================================\n",
        "vocab_file = None\n",
        "tokenizer = None\n",
        "model = None\n",
        "if model_name == 'bert':\n",
        "    vocab_file = 'bert-base-uncased'\n",
        "    tokenizer = transformers.BertTokenizer.from_pretrained(\n",
        "        vocab_file,do_lower_case=True)\n",
        "\n",
        "    model = transformers.BertForSequenceClassification.from_pretrained(\n",
        "        vocab_file, num_labels=num_labels)\n",
        "\n",
        "if model_name == 'distilbertfast':\n",
        "    vocab_file = 'distilbert-base-uncased'\n",
        "    tokenizer = transformers.DistilBertTokenizerFast.from_pretrained(\n",
        "        vocab_file,do_lower_case=True)\n",
        "\n",
        "    model = transformers.BertForSequenceClassification.from_pretrained(\n",
        "        vocab_file, num_labels=num_labels)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing BertForSequenceClassification: ['distilbert.embeddings.word_embeddings.weight', 'distilbert.embeddings.position_embeddings.weight', 'distilbert.embeddings.LayerNorm.weight', 'distilbert.embeddings.LayerNorm.bias', 'distilbert.transformer.layer.0.attention.q_lin.weight', 'distilbert.transformer.layer.0.attention.q_lin.bias', 'distilbert.transformer.layer.0.attention.k_lin.weight', 'distilbert.transformer.layer.0.attention.k_lin.bias', 'distilbert.transformer.layer.0.attention.v_lin.weight', 'distilbert.transformer.layer.0.attention.v_lin.bias', 'distilbert.transformer.layer.0.attention.out_lin.weight', 'distilbert.transformer.layer.0.attention.out_lin.bias', 'distilbert.transformer.layer.0.sa_layer_norm.weight', 'distilbert.transformer.layer.0.sa_layer_norm.bias', 'distilbert.transformer.layer.0.ffn.lin1.weight', 'distilbert.transformer.layer.0.ffn.lin1.bias', 'distilbert.transformer.layer.0.ffn.lin2.weight', 'distilbert.transformer.layer.0.ffn.lin2.bias', 'distilbert.transformer.layer.0.output_layer_norm.weight', 'distilbert.transformer.layer.0.output_layer_norm.bias', 'distilbert.transformer.layer.1.attention.q_lin.weight', 'distilbert.transformer.layer.1.attention.q_lin.bias', 'distilbert.transformer.layer.1.attention.k_lin.weight', 'distilbert.transformer.layer.1.attention.k_lin.bias', 'distilbert.transformer.layer.1.attention.v_lin.weight', 'distilbert.transformer.layer.1.attention.v_lin.bias', 'distilbert.transformer.layer.1.attention.out_lin.weight', 'distilbert.transformer.layer.1.attention.out_lin.bias', 'distilbert.transformer.layer.1.sa_layer_norm.weight', 'distilbert.transformer.layer.1.sa_layer_norm.bias', 'distilbert.transformer.layer.1.ffn.lin1.weight', 'distilbert.transformer.layer.1.ffn.lin1.bias', 'distilbert.transformer.layer.1.ffn.lin2.weight', 'distilbert.transformer.layer.1.ffn.lin2.bias', 'distilbert.transformer.layer.1.output_layer_norm.weight', 'distilbert.transformer.layer.1.output_layer_norm.bias', 'distilbert.transformer.layer.2.attention.q_lin.weight', 'distilbert.transformer.layer.2.attention.q_lin.bias', 'distilbert.transformer.layer.2.attention.k_lin.weight', 'distilbert.transformer.layer.2.attention.k_lin.bias', 'distilbert.transformer.layer.2.attention.v_lin.weight', 'distilbert.transformer.layer.2.attention.v_lin.bias', 'distilbert.transformer.layer.2.attention.out_lin.weight', 'distilbert.transformer.layer.2.attention.out_lin.bias', 'distilbert.transformer.layer.2.sa_layer_norm.weight', 'distilbert.transformer.layer.2.sa_layer_norm.bias', 'distilbert.transformer.layer.2.ffn.lin1.weight', 'distilbert.transformer.layer.2.ffn.lin1.bias', 'distilbert.transformer.layer.2.ffn.lin2.weight', 'distilbert.transformer.layer.2.ffn.lin2.bias', 'distilbert.transformer.layer.2.output_layer_norm.weight', 'distilbert.transformer.layer.2.output_layer_norm.bias', 'distilbert.transformer.layer.3.attention.q_lin.weight', 'distilbert.transformer.layer.3.attention.q_lin.bias', 'distilbert.transformer.layer.3.attention.k_lin.weight', 'distilbert.transformer.layer.3.attention.k_lin.bias', 'distilbert.transformer.layer.3.attention.v_lin.weight', 'distilbert.transformer.layer.3.attention.v_lin.bias', 'distilbert.transformer.layer.3.attention.out_lin.weight', 'distilbert.transformer.layer.3.attention.out_lin.bias', 'distilbert.transformer.layer.3.sa_layer_norm.weight', 'distilbert.transformer.layer.3.sa_layer_norm.bias', 'distilbert.transformer.layer.3.ffn.lin1.weight', 'distilbert.transformer.layer.3.ffn.lin1.bias', 'distilbert.transformer.layer.3.ffn.lin2.weight', 'distilbert.transformer.layer.3.ffn.lin2.bias', 'distilbert.transformer.layer.3.output_layer_norm.weight', 'distilbert.transformer.layer.3.output_layer_norm.bias', 'distilbert.transformer.layer.4.attention.q_lin.weight', 'distilbert.transformer.layer.4.attention.q_lin.bias', 'distilbert.transformer.layer.4.attention.k_lin.weight', 'distilbert.transformer.layer.4.attention.k_lin.bias', 'distilbert.transformer.layer.4.attention.v_lin.weight', 'distilbert.transformer.layer.4.attention.v_lin.bias', 'distilbert.transformer.layer.4.attention.out_lin.weight', 'distilbert.transformer.layer.4.attention.out_lin.bias', 'distilbert.transformer.layer.4.sa_layer_norm.weight', 'distilbert.transformer.layer.4.sa_layer_norm.bias', 'distilbert.transformer.layer.4.ffn.lin1.weight', 'distilbert.transformer.layer.4.ffn.lin1.bias', 'distilbert.transformer.layer.4.ffn.lin2.weight', 'distilbert.transformer.layer.4.ffn.lin2.bias', 'distilbert.transformer.layer.4.output_layer_norm.weight', 'distilbert.transformer.layer.4.output_layer_norm.bias', 'distilbert.transformer.layer.5.attention.q_lin.weight', 'distilbert.transformer.layer.5.attention.q_lin.bias', 'distilbert.transformer.layer.5.attention.k_lin.weight', 'distilbert.transformer.layer.5.attention.k_lin.bias', 'distilbert.transformer.layer.5.attention.v_lin.weight', 'distilbert.transformer.layer.5.attention.v_lin.bias', 'distilbert.transformer.layer.5.attention.out_lin.weight', 'distilbert.transformer.layer.5.attention.out_lin.bias', 'distilbert.transformer.layer.5.sa_layer_norm.weight', 'distilbert.transformer.layer.5.sa_layer_norm.bias', 'distilbert.transformer.layer.5.ffn.lin1.weight', 'distilbert.transformer.layer.5.ffn.lin1.bias', 'distilbert.transformer.layer.5.ffn.lin2.weight', 'distilbert.transformer.layer.5.ffn.lin2.bias', 'distilbert.transformer.layer.5.output_layer_norm.weight', 'distilbert.transformer.layer.5.output_layer_norm.bias', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['embeddings.word_embeddings.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.LayerNorm.weight', 'embeddings.LayerNorm.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.output.dense.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.LayerNorm.bias', 'pooler.dense.weight', 'pooler.dense.bias', 'classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y7k3W0Bf3Ot5"
      },
      "source": [
        "## Load pretrained tokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xehSlt_O3OwU"
      },
      "source": [
        "Transformers pretrained tokenizers\n",
        "\n",
        "```python\n",
        "BERT:\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True) \n",
        "\n",
        "XLNet:\n",
        "tokenizer = XLNetTokenizer.from_pretrained('xlnet-base-cased', do_lower_case=False) \n",
        "\n",
        "RoBERTa:\n",
        "tokenizer = RobertaTokenizer.from_pretrained('roberta-base', do_lower_case=False)\n",
        "\n",
        "DistilBert:\n",
        "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base', do_lower_case=False)\n",
        "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base', do_lower_case=False)\n",
        "```\n",
        "\n",
        "transformers.MyTokenizer.from_pretrained\n",
        "```\n",
        "from_pretrained(pretrained_model_name_or_path, *init_inputs, **kwargs)\n",
        "\n",
        "```\n",
        "\n",
        "\n",
        "Distilbert hugging face: https://huggingface.co/transformers/model_doc/distilbert.html\n",
        "\n",
        "```python\n",
        "transformers.DistilBertConfig(\n",
        "vocab_size=30522,\n",
        "max_position_embeddings=512,\n",
        "sinusoidal_pos_embds=False, \n",
        "n_layers=6, \n",
        "n_heads=12, \n",
        "dim=768, \n",
        "hidden_dim=3072, \n",
        "dropout=0.1, \n",
        "attention_dropout=0.1, \n",
        "activation='gelu', \n",
        "initializer_range=0.02, \n",
        "qa_dropout=0.1, \n",
        "seq_classif_dropout=0.2, \n",
        "pad_token_id=0, \n",
        "**kwargs)\n",
        "```\n",
        "\n",
        "```python\n",
        "transformers.DistilBertTokenizerFast(vocab_file,\n",
        "tokenizer_file=None,\n",
        "do_lower_case=True,\n",
        "unk_token='[UNK]',\n",
        "sep_token='[SEP]',\n",
        "pad_token='[PAD]',\n",
        "cls_token='[CLS]',\n",
        "mask_token='[MASK]',\n",
        "tokenize_chinese_chars=True,\n",
        "strip_accents=None,\n",
        "**kwargs)\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vS5wBPBp3Ozq"
      },
      "source": [
        "# show_methods(transformers,3,contains='Tokenizer')"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3ed86V93O22"
      },
      "source": [
        "# show_methods(transformers.DistilBertTokenizerFast,2)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-S7H6irB3O6h"
      },
      "source": [
        "# vocab_file = 'distilbert-base-uncased'\n",
        "# tokenizer = transformers.DistilBertTokenizerFast.from_pretrained(\n",
        "#     vocab_file,do_lower_case=True)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zGqciCT42rKS"
      },
      "source": [
        "## Get Encodings from tokenizer\n",
        "\n",
        "Tokenizer: https://huggingface.co/transformers/main_classes/tokenizer.html\n",
        "```python\n",
        "batch_encode_plus(batch_text_or_text_pairs,\n",
        "add_special_tokens=True,\n",
        "padding=False,\n",
        "truncation=False,\n",
        "max_length=None,\n",
        "stride=0,\n",
        "is_split_into_words=False,\n",
        "pad_to_multiple_of=None,\n",
        "return_tensors=None,\n",
        "return_token_type_ids=None,\n",
        "return_attention_mask=None,\n",
        "return_overflowing_tokens=False,\n",
        "return_special_tokens_mask=False,\n",
        "return_offsets_mapping=False,\n",
        "return_length=False,\n",
        "verbose=True,\n",
        "**kwargs)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O1KSTbVl2r2V"
      },
      "source": [
        "# help(tokenizer.batch_encode_plus)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NTpKL5-42r9B",
        "outputId": "e89a638e-151b-462b-dc01-a0b593db7c1d"
      },
      "source": [
        "%%time\n",
        "max_length = 100 # choose about 100 for colab\n",
        "encodings = tokenizer.batch_encode_plus(list_text,\n",
        "                max_length=max_length,\n",
        "                truncation=True, # if you choose false, colab will crash\n",
        "                return_token_type_ids=True,\n",
        "                padding=True)\n",
        "\n",
        "print('tokenizer outputs: ', encodings.keys())\n",
        " \n",
        "# dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])\n",
        "\n",
        "# colab error: Your session crashed after using all available RAM."
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tokenizer outputs:  dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])\n",
            "CPU times: user 52.4 s, sys: 1.17 s, total: 53.6 s\n",
            "Wall time: 15.9 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBf6Z7dQ2sCf"
      },
      "source": [
        "input_ids       = encodings['input_ids']\n",
        "token_type_ids  = encodings['token_type_ids']\n",
        "attention_masks = encodings['attention_mask']"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3evL-y8E2sHA"
      },
      "source": [
        "## Find One-freq rows to exclude from stratify split\n",
        "\n",
        "- df\\_train has ohe column called `one_hot_labels` having `N_CLASSES` list.\n",
        "- Find value counts of all ohe rows\n",
        "- If a row is unique, keep it separate.\n",
        "- Stratify split other rows\n",
        "- In the end, combine these one freq rows."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NYUUMCS42sKg",
        "outputId": "1b3b5e34-3d56-41f3-f4da-bb02ed7664f6"
      },
      "source": [
        "# the ohe col has N_classes in a single list\n",
        "# if a row is unique, we will not stratify split it.\n",
        "df_train[col_ohe].head()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    [0, 0, 0, 0, 0, 0]\n",
              "1    [0, 0, 0, 0, 0, 0]\n",
              "2    [0, 0, 0, 0, 0, 0]\n",
              "3    [0, 0, 0, 0, 0, 0]\n",
              "4    [0, 0, 0, 0, 0, 0]\n",
              "Name: one_hot_labels, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ir1n4b232sOl",
        "outputId": "1a0c264f-2f8c-40b9-b73a-b2b0a533ecf9"
      },
      "source": [
        "label_counts = df_train[col_ohe].astype(str).value_counts()\n",
        "one_freq = label_counts[label_counts==1].keys()\n",
        "\n",
        "cond = df_train[col_ohe].astype(str).isin(one_freq)\n",
        "one_freq_idxs = df_train[cond].index\n",
        "one_freq_idxs = sorted(list(one_freq_idxs), reverse=True)\n",
        "\n",
        "print('df_train label indices with only one instance: ', one_freq_idxs)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "df_train label indices with only one instance:  [113097, 57059, 7039]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k2kTMYN32sRT"
      },
      "source": [
        "# get single freq rows\n",
        "# (we will pop from original data and will combine later)\n",
        "\n",
        "one_freq_input_ids       = [input_ids.pop(i)       for i in one_freq_idxs]\n",
        "one_freq_token_types     = [token_type_ids.pop(i)  for i in one_freq_idxs]\n",
        "one_freq_attention_masks = [attention_masks.pop(i) for i in one_freq_idxs]\n",
        "one_freq_labels          = [labels.pop(i)          for i in one_freq_idxs]"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tZvryp9r2sWU"
      },
      "source": [
        "# Get train validation tensors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lZfGYnOy2sZB",
        "outputId": "e9cd598f-45fe-4518-fcaf-4d22cafb8c31"
      },
      "source": [
        "%%time\n",
        "\n",
        "# train valid split using stratify\n",
        "# Here we use only ohe rows that have freq count > 1\n",
        "train_inputs, valid_inputs,\\\n",
        "train_labels, valid_labels,\\\n",
        "train_token_types, valid_token_types,\\\n",
        "train_masks, valid_masks\\\n",
        "  = train_test_split(input_ids, labels, token_type_ids,attention_masks,\n",
        "                    random_state=SEED,\n",
        "                    test_size=0.10,\n",
        "                    stratify = labels)\n",
        "\n",
        "# After stratify split, we combine back one-freq rows\n",
        "train_inputs.extend(one_freq_input_ids)\n",
        "train_labels.extend(one_freq_labels)\n",
        "train_masks.extend(one_freq_attention_masks)\n",
        "train_token_types.extend(one_freq_token_types)\n",
        "\n",
        "# Create torch tensors\n",
        "train_inputs      = torch.tensor(train_inputs)\n",
        "train_labels      = torch.tensor(train_labels)\n",
        "train_masks       = torch.tensor(train_masks)\n",
        "train_token_types = torch.tensor(train_token_types)\n",
        "\n",
        "valid_inputs      = torch.tensor(valid_inputs)\n",
        "valid_labels      = torch.tensor(valid_labels)\n",
        "valid_masks       = torch.tensor(valid_masks)\n",
        "valid_token_types = torch.tensor(valid_token_types)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 2.96 s, sys: 70.2 ms, total: 3.03 s\n",
            "Wall time: 3.03 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ubtRgpNl4Rwc"
      },
      "source": [
        "## Get TensorDataset, Sampler and DataLoader\n",
        "- Random Sampler for train data\n",
        "- Sequential Sampler for valid data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mIG9H_S24USI"
      },
      "source": [
        "from torch.utils.data import (TensorDataset, DataLoader,\n",
        "                              RandomSampler, SequentialSampler)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ryFQm21F4UxE"
      },
      "source": [
        "# Select a batch size for training.\n",
        "# For fine-tuning with XLNet, the authors recommend\n",
        "# a batch size of 32, 48, or 128.\n",
        "# We will use 32 here to avoid memory issues.\n",
        "batch_size = 32\n",
        "\n",
        "# Create an iterator of our data with torch DataLoader.\n",
        "# This helps save on memory during training because, unlike a for loop, \n",
        "# with an iterator the entire dataset does not need to be loaded into memory\n",
        "\n",
        "train_data       = TensorDataset(train_inputs, train_masks,\n",
        "                                 train_labels, train_token_types)\n",
        "train_sampler    = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler,\n",
        "                              batch_size=batch_size)\n",
        "\n",
        "valid_data       = TensorDataset(valid_inputs, valid_masks,\n",
        "                                 valid_labels, valid_token_types)\n",
        "valid_sampler    = SequentialSampler(valid_data)\n",
        "valid_dataloader = DataLoader(valid_data, sampler=valid_sampler,\n",
        "                              batch_size=batch_size)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iSgK-YL64U0U"
      },
      "source": [
        "# # save data loaders\n",
        "# torch.save(train_dataloader,'train_data_loader')\n",
        "# torch.save(valid_dataloader,'valid_data_loader')"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GestF2tI4U2s"
      },
      "source": [
        "## Load the Model for Sequence Classification\n",
        "\n",
        "```python\n",
        "BERT:\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True) \n",
        "\n",
        "XLNet:\n",
        "tokenizer = XLNetTokenizer.from_pretrained('xlnet-base-cased', do_lower_case=False) \n",
        "\n",
        "RoBERTa:\n",
        "tokenizer = RobertaTokenizer.from_pretrained('roberta-base', do_lower_case=False)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 576
        },
        "id": "2DhdjPfM4U5a",
        "outputId": "26a41b79-aa89-4a07-b7b5-0871da24f5e4"
      },
      "source": [
        "show_methods(transformers,contains='SequenceClassification',ncols=2)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>AlbertForSequenceClassification</td>\n",
              "      <td>TFAlbertForSequenceClassification</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>AutoModelForSequenceClassification</td>\n",
              "      <td>TFAutoModelForSequenceClassification</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>BartForSequenceClassification</td>\n",
              "      <td>TFBertForSequenceClassification</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>BertForSequenceClassification</td>\n",
              "      <td>TFCamembertForSequenceClassification</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>CamembertForSequenceClassification</td>\n",
              "      <td>TFDistilBertForSequenceClassification</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>DebertaForSequenceClassification</td>\n",
              "      <td>TFElectraForSequenceClassification</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>DistilBertForSequenceClassification</td>\n",
              "      <td>TFFlaubertForSequenceClassification</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>ElectraForSequenceClassification</td>\n",
              "      <td>TFFunnelForSequenceClassification</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>FlaubertForSequenceClassification</td>\n",
              "      <td>TFLongformerForSequenceClassification</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>FunnelForSequenceClassification</td>\n",
              "      <td>TFMobileBertForSequenceClassification</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>GPT2ForSequenceClassification</td>\n",
              "      <td>TFRobertaForSequenceClassification</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>LongformerForSequenceClassification</td>\n",
              "      <td>TFXLMForSequenceClassification</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>MobileBertForSequenceClassification</td>\n",
              "      <td>TFXLMRobertaForSequenceClassification</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>OpenAIGPTForSequenceClassification</td>\n",
              "      <td>TFXLNetForSequenceClassification</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>ReformerForSequenceClassification</td>\n",
              "      <td>XLMForSequenceClassification</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>RobertaForSequenceClassification</td>\n",
              "      <td>XLMRobertaForSequenceClassification</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>SqueezeBertForSequenceClassification</td>\n",
              "      <td>XLNetForSequenceClassification</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                       0                                      1\n",
              "0        AlbertForSequenceClassification      TFAlbertForSequenceClassification\n",
              "1     AutoModelForSequenceClassification   TFAutoModelForSequenceClassification\n",
              "2          BartForSequenceClassification        TFBertForSequenceClassification\n",
              "3          BertForSequenceClassification   TFCamembertForSequenceClassification\n",
              "4     CamembertForSequenceClassification  TFDistilBertForSequenceClassification\n",
              "5       DebertaForSequenceClassification     TFElectraForSequenceClassification\n",
              "6    DistilBertForSequenceClassification    TFFlaubertForSequenceClassification\n",
              "7       ElectraForSequenceClassification      TFFunnelForSequenceClassification\n",
              "8      FlaubertForSequenceClassification  TFLongformerForSequenceClassification\n",
              "9        FunnelForSequenceClassification  TFMobileBertForSequenceClassification\n",
              "10         GPT2ForSequenceClassification     TFRobertaForSequenceClassification\n",
              "11   LongformerForSequenceClassification         TFXLMForSequenceClassification\n",
              "12   MobileBertForSequenceClassification  TFXLMRobertaForSequenceClassification\n",
              "13    OpenAIGPTForSequenceClassification       TFXLNetForSequenceClassification\n",
              "14     ReformerForSequenceClassification           XLMForSequenceClassification\n",
              "15      RobertaForSequenceClassification    XLMRobertaForSequenceClassification\n",
              "16  SqueezeBertForSequenceClassification         XLNetForSequenceClassification"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WdKpq8Tc4U-G",
        "outputId": "9fe5b739-7e1d-4765-efb0-44c2f0ecc418"
      },
      "source": [
        "# %%time\n",
        "\n",
        "# # num_labels = len(cols_label) # NUM_CLASSES\n",
        "# # model = transformers.BertForSequenceClassification.from_pretrained(\n",
        "# #     vocab_file, num_labels=num_labels)\n",
        "\n",
        "model.cuda()\n",
        "print('using cuda')"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "using cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "id": "j42tqLal4VBV",
        "outputId": "d5f4d0cb-3614-45d0-8df6-7e56532cd948"
      },
      "source": [
        "show_methods(model)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>T_destination</td>\n",
              "      <td>device</td>\n",
              "      <td>greedy_search</td>\n",
              "      <td>register_buffer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>add_memory_hooks</td>\n",
              "      <td>double</td>\n",
              "      <td>half</td>\n",
              "      <td>register_forward_hook</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>add_module</td>\n",
              "      <td>dropout</td>\n",
              "      <td>init_weights</td>\n",
              "      <td>register_forward_pre_hook</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>adjust_logits_during_generation</td>\n",
              "      <td>dtype</td>\n",
              "      <td>invert_attention_mask</td>\n",
              "      <td>register_parameter</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>apply</td>\n",
              "      <td>dummy_inputs</td>\n",
              "      <td>load_state_dict</td>\n",
              "      <td>requires_grad_</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>base_model</td>\n",
              "      <td>dump_patches</td>\n",
              "      <td>load_tf_weights</td>\n",
              "      <td>reset_memory_hooks_state</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>base_model_prefix</td>\n",
              "      <td>estimate_tokens</td>\n",
              "      <td>modules</td>\n",
              "      <td>resize_token_embeddings</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>beam_sample</td>\n",
              "      <td>eval</td>\n",
              "      <td>name_or_path</td>\n",
              "      <td>sample</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>beam_search</td>\n",
              "      <td>extra_repr</td>\n",
              "      <td>named_buffers</td>\n",
              "      <td>save_pretrained</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>bert</td>\n",
              "      <td>float</td>\n",
              "      <td>named_children</td>\n",
              "      <td>set_input_embeddings</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>bfloat16</td>\n",
              "      <td>floating_point_ops</td>\n",
              "      <td>named_modules</td>\n",
              "      <td>share_memory</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>buffers</td>\n",
              "      <td>forward</td>\n",
              "      <td>named_parameters</td>\n",
              "      <td>state_dict</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>children</td>\n",
              "      <td>from_pretrained</td>\n",
              "      <td>num_labels</td>\n",
              "      <td>tie_weights</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>classifier</td>\n",
              "      <td>generate</td>\n",
              "      <td>num_parameters</td>\n",
              "      <td>to</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>config</td>\n",
              "      <td>get_extended_attention_mask</td>\n",
              "      <td>parameters</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>config_class</td>\n",
              "      <td>get_head_mask</td>\n",
              "      <td>prepare_inputs_for_generation</td>\n",
              "      <td>training</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>cpu</td>\n",
              "      <td>get_input_embeddings</td>\n",
              "      <td>prune_heads</td>\n",
              "      <td>type</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>cuda</td>\n",
              "      <td>get_output_embeddings</td>\n",
              "      <td>register_backward_hook</td>\n",
              "      <td>zero_grad</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                  0  ...                          3\n",
              "0                     T_destination  ...            register_buffer\n",
              "1                  add_memory_hooks  ...      register_forward_hook\n",
              "2                        add_module  ...  register_forward_pre_hook\n",
              "3   adjust_logits_during_generation  ...         register_parameter\n",
              "4                             apply  ...             requires_grad_\n",
              "5                        base_model  ...   reset_memory_hooks_state\n",
              "6                 base_model_prefix  ...    resize_token_embeddings\n",
              "7                       beam_sample  ...                     sample\n",
              "8                       beam_search  ...            save_pretrained\n",
              "9                              bert  ...       set_input_embeddings\n",
              "10                         bfloat16  ...               share_memory\n",
              "11                          buffers  ...                 state_dict\n",
              "12                         children  ...                tie_weights\n",
              "13                       classifier  ...                         to\n",
              "14                           config  ...                      train\n",
              "15                     config_class  ...                   training\n",
              "16                              cpu  ...                       type\n",
              "17                             cuda  ...                  zero_grad\n",
              "\n",
              "[18 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jfEwhgaP4VEQ"
      },
      "source": [
        "## Choose Optimizer\n",
        "\n",
        "Optimizer AdamW\n",
        "- https://huggingface.co/transformers/main_classes/optimizer_schedules.html\n",
        "\n",
        "```python\n",
        "classtransformers.AdamW(params,\n",
        "lr          : 0.001,\n",
        "betas       : 0.9, 0.999,\n",
        "eps         : 1e-06,\n",
        "weight_decay:  0.0,\n",
        "correct_bias: True\n",
        ")\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "W85NvqxK4lMk",
        "outputId": "d469ee9c-3b06-4706-cb5a-bd317f42d50e"
      },
      "source": [
        "show_methods(transformers,3,contains='Adam')"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>AdamW</td>\n",
              "      <td>AdamWeightDecay</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       0                1 2\n",
              "0  AdamW  AdamWeightDecay  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hdpbBoG64lP1"
      },
      "source": [
        "# setting custom optimization parameters.\n",
        "params_opt = list(model.named_parameters()) # this is a list\n",
        "\n",
        "no_decay = ['bias', 'gamma', 'beta']\n",
        "\n",
        "\n",
        "params_opt_group = [\n",
        "    # non decay params\n",
        "    {'params': [p for n, p in params_opt\n",
        "                if not any(nd in n for nd in no_decay)],\n",
        "     'weight_decay_rate': 0.01},\n",
        "\n",
        "    # decay params\n",
        "    {'params': [p for n, p in params_opt\n",
        "                if any(nd in n for nd in no_decay)],\n",
        "     'weight_decay_rate': 0.0}\n",
        "]"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "usIcxnjR4lSp",
        "outputId": "bda8c4c1-73a8-4a26-f31f-3c6775bebb18"
      },
      "source": [
        "print(len(params_opt))\n",
        "# print(params_opt[0])\n",
        "print(params_opt[-1])"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "201\n",
            "('classifier.bias', Parameter containing:\n",
            "tensor([0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "G3uhOibR4lVw",
        "outputId": "354fa913-8a46-4322-fd47-dfd6c352f33d"
      },
      "source": [
        "params_opt[0][0] # key is string"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'bert.embeddings.word_embeddings.weight'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2e5moG_14lZX",
        "outputId": "d4a578e5-7b59-401a-8390-353ac1270f06"
      },
      "source": [
        "params_opt[0][1][0][:2] # value is tensor"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.0015, -0.0127], device='cuda:0', grad_fn=<SliceBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ANN0byY4lb5"
      },
      "source": [
        "optimizer = transformers.AdamW(params_opt_group,lr=2e-5,correct_bias=True)\n",
        "# optimizer = AdamW(model.parameters(),lr=2e-5)  # Default optimization"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2PrdKTqu4ldr"
      },
      "source": [
        "## Train Model using Torch\n",
        "\n",
        "BCE with Logit Loss\n",
        "- https://pytorch.org/docs/stable/generated/torch.nn.BCEWithLogitsLoss.html\n",
        "```python\n",
        "torch.nn.BCEWithLogitsLoss(weight: None,\n",
        "size_average=None,\n",
        "reduce=None,\n",
        "reduction:'mean',\n",
        "pos_weight:None\n",
        ")\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "huiIwy2X4ykG"
      },
      "source": [
        "from torch.nn import BCEWithLogitsLoss, BCELoss\n",
        "from tqdm import trange"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oFY6nYzo4yoQ",
        "outputId": "da2f5fd2-5321-4042-9dcc-6d6203363b82"
      },
      "source": [
        "# Store our loss and accuracy for plotting\n",
        "train_loss_set = []\n",
        "\n",
        "# Number of training epochs (authors recommend between 2 and 4 for xlnet)\n",
        "epochs = 3\n",
        "\n",
        "# trange is a tqdm wrapper around the normal python range\n",
        "for _ in trange(epochs, desc=\"Epoch\"):\n",
        "\n",
        "  # Training\n",
        "  \n",
        "  # train model\n",
        "  model.train()\n",
        "\n",
        "  # Tracking variables\n",
        "  tr_loss = 0\n",
        "  nb_tr_examples, nb_tr_steps = 0, 0\n",
        "  \n",
        "  # Train the data for one epoch\n",
        "  for step, batch in enumerate(train_dataloader):\n",
        "    # Add batch to GPU\n",
        "    batch = tuple(b.to(device) for b in batch)\n",
        "\n",
        "    # Unpack the inputs from our dataloader\n",
        "    b_input_ids, b_input_mask, b_labels, b_token_types = batch\n",
        "\n",
        "    # Clear out the gradients (by default they accumulate)\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # # Forward pass for multiclass classification\n",
        "    # outputs = model(b_input_ids, token_type_ids=None,\n",
        "    #                  attention_mask=b_input_mask, labels=b_labels)\n",
        "    # loss = outputs[0]\n",
        "    # logits = outputs[1]\n",
        "\n",
        "    # Forward pass for multilabel classification\n",
        "    outputs = model(b_input_ids,\n",
        "                    token_type_ids=None,\n",
        "                    attention_mask=b_input_mask)\n",
        "    logits = outputs[0]\n",
        "    loss_func = BCEWithLogitsLoss()\n",
        "    loss = loss_func(logits.view(-1,num_labels),\n",
        "                     b_labels.type_as(logits).view(-1,num_labels))\n",
        "    # loss_func = BCELoss() \n",
        "    # loss = loss_func(torch.sigmoid(logits.view(-1,num_labels)),\n",
        "    #             b_labels.type_as(logits).view(-1,num_labels))\n",
        "    train_loss_set.append(loss.item())    \n",
        "\n",
        "    # Backward pass\n",
        "    loss.backward()\n",
        "\n",
        "    # Update parameters and take a step using the computed gradient\n",
        "    optimizer.step()\n",
        "    # scheduler.step()\n",
        "\n",
        "    # Update tracking variables\n",
        "    tr_loss += loss.item()\n",
        "    nb_tr_examples += b_input_ids.size(0)\n",
        "    nb_tr_steps += 1\n",
        "\n",
        "  print(\"Train loss: {}\".format(tr_loss/nb_tr_steps))\n",
        "\n",
        "###############################################################################\n",
        "\n",
        "  # Validation\n",
        "\n",
        "  # Put model in evaluation mode to evaluate loss on the validation set\n",
        "  model.eval()\n",
        "\n",
        "  # Variables to gather full output\n",
        "  logit_preds,true_labels,pred_labels,tokenized_texts = [],[],[],[]\n",
        "\n",
        "  # Predict\n",
        "  #=======================================================================\n",
        "  for i, batch in enumerate(valid_dataloader):\n",
        "    batch = tuple(b.to(device) for b in batch)\n",
        "\n",
        "    # Unpack the inputs from our dataloader\n",
        "    b_input_ids, b_input_mask, b_labels, b_token_types = batch\n",
        "\n",
        "    with torch.no_grad():\n",
        "      # Forward pass\n",
        "      outs = model(b_input_ids, token_type_ids=None,\n",
        "                   attention_mask=b_input_mask)\n",
        "      b_logit_pred = outs[0]\n",
        "      pred_label = torch.sigmoid(b_logit_pred)\n",
        "\n",
        "      b_logit_pred = b_logit_pred.detach().cpu().numpy()\n",
        "      pred_label = pred_label.to('cpu').numpy()\n",
        "      b_labels = b_labels.to('cpu').numpy()\n",
        "\n",
        "    tokenized_texts.append(b_input_ids)\n",
        "    logit_preds.append(b_logit_pred)\n",
        "    true_labels.append(b_labels)\n",
        "    pred_labels.append(pred_label)\n",
        "\n",
        "  #========================================================================\n",
        "  # Flatten outputs\n",
        "  pred_labels = [item for sublist in pred_labels for item in sublist]\n",
        "  true_labels = [item for sublist in true_labels for item in sublist]\n",
        "\n",
        "  # Calculate Accuracy\n",
        "  threshold = 0.50\n",
        "  pred_bools = [pl>threshold for pl in pred_labels]\n",
        "  true_bools = [tl==1 for tl in true_labels]\n",
        "  val_f1_accuracy = f1_score(true_bools,pred_bools,average='micro')*100\n",
        "  val_flat_accuracy = accuracy_score(true_bools, pred_bools)*100\n",
        "\n",
        "  print('F1 Validation Accuracy: ', val_f1_accuracy)\n",
        "  print('Flat Validation Accuracy: ', val_flat_accuracy)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:   0%|          | 0/3 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss: 0.07192983261874426\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  33%|      | 1/3 [16:54<33:49, 1014.81s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "F1 Validation Accuracy:  64.4510657804263\n",
            "Flat Validation Accuracy:  91.540028199906\n",
            "Train loss: 0.050434639209280256\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  67%|   | 2/3 [33:48<16:54, 1014.52s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "F1 Validation Accuracy:  73.57074109720885\n",
            "Flat Validation Accuracy:  92.0491931693561\n",
            "Train loss: 0.045808715516655565\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 100%|| 3/3 [50:42<00:00, 1014.23s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "F1 Validation Accuracy:  70.7133917396746\n",
            "Flat Validation Accuracy:  92.02569324768918\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJV5EBU34yql"
      },
      "source": [
        "#  torch.save(model.state_dict(), 'bert_model_toxic')"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FSiDQP304ys-"
      },
      "source": [
        "## Load and Preprocess Test Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XnnMKPDC4yvk",
        "outputId": "af8a45bb-39f8-4ac7-aaf8-ab81a14f3600"
      },
      "source": [
        "cols_label"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "id": "_t9OX4fn4yyN",
        "outputId": "04562fb6-c2a9-4d93-ca3b-f5175dd54d03"
      },
      "source": [
        "df_test = pd.read_csv('test.csv')\n",
        "df_test.head(2)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>comment_text</th>\n",
              "      <th>toxic</th>\n",
              "      <th>severe_toxic</th>\n",
              "      <th>obscene</th>\n",
              "      <th>threat</th>\n",
              "      <th>insult</th>\n",
              "      <th>identity_hate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>70bbc3e96dd459b1</td>\n",
              "      <td>Hammed it is, cheers!</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0b2e86f819b4b9a4</td>\n",
              "      <td>Not a problem, sorry for the inconvenience and...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 id  ... identity_hate\n",
              "0  70bbc3e96dd459b1  ...             0\n",
              "1  0b2e86f819b4b9a4  ...             0\n",
              "\n",
              "[2 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_F25DVuL4y09",
        "outputId": "6e6c3f79-e604-42c5-cb97-d2db94f3b468"
      },
      "source": [
        "print('Count of 1 per label: \\n', df_test[cols_label].sum(), '\\n') \n",
        "print('Count of 0 per label: \\n', df_test[cols_label].eq(0).sum())"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Count of 1 per label: \n",
            " toxic            3092\n",
            "severe_toxic      313\n",
            "obscene          1667\n",
            "threat             99\n",
            "insult           1585\n",
            "identity_hate     269\n",
            "dtype: int64 \n",
            "\n",
            "Count of 0 per label: \n",
            " toxic            28823\n",
            "severe_toxic     31602\n",
            "obscene          30248\n",
            "threat           31816\n",
            "insult           30330\n",
            "identity_hate    31646\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i2DyqGr04y4S",
        "outputId": "a16ee00f-f05c-43e7-b1f1-ad9cbb0ffb89"
      },
      "source": [
        "df_test.isna().sum().sum()"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "id": "5yJ7HRWv4y67",
        "outputId": "06562856-0d84-4a64-c6cc-3aef1853da53"
      },
      "source": [
        "df_test[col_ohe] = df_test[cols_label].to_numpy().tolist()\n",
        "df_test.head(2)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>comment_text</th>\n",
              "      <th>toxic</th>\n",
              "      <th>severe_toxic</th>\n",
              "      <th>obscene</th>\n",
              "      <th>threat</th>\n",
              "      <th>insult</th>\n",
              "      <th>identity_hate</th>\n",
              "      <th>one_hot_labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>70bbc3e96dd459b1</td>\n",
              "      <td>Hammed it is, cheers!</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0b2e86f819b4b9a4</td>\n",
              "      <td>Not a problem, sorry for the inconvenience and...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 id  ...      one_hot_labels\n",
              "0  70bbc3e96dd459b1  ...  [0, 0, 0, 0, 0, 0]\n",
              "1  0b2e86f819b4b9a4  ...  [0, 0, 0, 0, 0, 0]\n",
              "\n",
              "[2 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5PK-Ndw4y-R"
      },
      "source": [
        "# Gathering input data\n",
        "test_labels   = list(df_test[cols_label].values)\n",
        "test_comments = list(df_test[col_text].values)"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xQTy_5Ox4lfV"
      },
      "source": [
        "## Tokenize Test Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oan6uqMp5RKm",
        "outputId": "eb84c6db-4ee0-44ae-b309-d621d625fd67"
      },
      "source": [
        "%%time\n",
        "# Encoding input data\n",
        "test_encodings       = tokenizer.batch_encode_plus(test_comments,\n",
        "                                max_length=max_length,\n",
        "                                return_token_type_ids=True,\n",
        "                                pad_to_max_length=True)\n",
        "test_input_ids       = test_encodings['input_ids']\n",
        "test_token_type_ids  = test_encodings['token_type_ids']\n",
        "test_attention_masks = test_encodings['attention_mask']"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2142: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 11.4 s, sys: 50.6 ms, total: 11.5 s\n",
            "Wall time: 3.18 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4chbjWLy5RO8"
      },
      "source": [
        "## Create Tensors for Test Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cB-VpSD55RSv"
      },
      "source": [
        "# Make tensors out of data\n",
        "test_inputs      = torch.tensor(test_input_ids)\n",
        "test_labels      = torch.tensor(test_labels)\n",
        "test_masks       = torch.tensor(test_attention_masks)\n",
        "test_token_types = torch.tensor(test_token_type_ids)"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VMEcjUiJ5RWp"
      },
      "source": [
        "## Create DataLoader for Test Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dju-2Nta5RaQ"
      },
      "source": [
        "# Create test dataloader\n",
        "test_data       = TensorDataset(test_inputs, test_masks, test_labels,\n",
        "                                test_token_types)\n",
        "test_sampler    = SequentialSampler(test_data)\n",
        "test_dataloader = DataLoader(test_data, sampler=test_sampler,\n",
        "                             batch_size=batch_size)\n",
        "\n",
        "# Save test dataloader\n",
        "torch.save(test_dataloader,'test_data_loader')"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ayz4v5pA5RdL"
      },
      "source": [
        "## Get the Predictions from Test Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tgj7J_vb5RhN",
        "outputId": "2e1812d4-bdc7-4fa3-ee6d-2e5624b9ce97"
      },
      "source": [
        "%%time\n",
        "# Test\n",
        "\n",
        "# Put model in evaluation mode to evaluate loss on the validation set\n",
        "model.eval()\n",
        "\n",
        "#track variables\n",
        "logit_preds,true_labels,pred_labels,tokenized_texts = [],[],[],[]\n",
        "\n",
        "# Predict\n",
        "for i, batch in enumerate(test_dataloader):\n",
        "  batch = tuple(b.to(device) for b in batch)\n",
        "\n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids, b_input_mask, b_labels, b_token_types = batch\n",
        "\n",
        "  with torch.no_grad():\n",
        "    # Forward pass\n",
        "    outs         = model(b_input_ids, token_type_ids=None,\n",
        "                         attention_mask=b_input_mask)\n",
        "    b_logit_pred = outs[0]\n",
        "    pred_label   = torch.sigmoid(b_logit_pred)\n",
        "\n",
        "    b_logit_pred = b_logit_pred.detach().cpu().numpy()\n",
        "    pred_label   = pred_label.to('cpu').numpy()\n",
        "    b_labels     = b_labels.to('cpu').numpy()\n",
        "\n",
        "  tokenized_texts.append(b_input_ids)\n",
        "  logit_preds.append(b_logit_pred)\n",
        "  true_labels.append(b_labels)\n",
        "  pred_labels.append(pred_label)\n",
        "\n",
        "# Flatten outputs\n",
        "tokenized_texts = [item  for sublist in tokenized_texts for item in sublist]\n",
        "pred_labels     = [item  for sublist in pred_labels     for item in sublist]\n",
        "true_labels     = [item  for sublist in true_labels     for item in sublist]\n",
        "true_bools      = [tl==1 for tl      in true_labels]"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 58.9 s, sys: 30.6 s, total: 1min 29s\n",
            "Wall time: 1min 29s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dTC5Zcde5Rj-",
        "outputId": "b6ccc3f6-6870-4353-f964-fb4ca3172150"
      },
      "source": [
        "print('pred_lables', pred_labels[:2])\n",
        "print('true_lables', true_labels[:2])\n",
        "print('true_bools', true_bools[:2])"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "pred_lables [array([2.11265427e-03, 9.95524388e-05, 7.45381229e-04, 1.11659254e-04,\n",
            "       6.03488996e-04, 2.03356976e-04], dtype=float32), array([0.00150312, 0.00014245, 0.00088974, 0.00013881, 0.00066261,\n",
            "       0.00023769], dtype=float32)]\n",
            "true_lables [array([0, 0, 0, 0, 0, 0]), array([0, 0, 0, 0, 0, 0])]\n",
            "true_bools [array([False, False, False, False, False, False]), array([False, False, False, False, False, False])]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_wk-Px455Rmv"
      },
      "source": [
        "# Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KVDFjHFh5Rp5",
        "outputId": "1b40874e-2d73-4ece-ed92-59d488e47790"
      },
      "source": [
        "len(true_bools), df_test.shape"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(31915, (31915, 9))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "btrVA0J75RtU"
      },
      "source": [
        "pred_bools = [pl>0.50 for pl in pred_labels]"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a3_cCMbn5Rvq",
        "outputId": "7d4a4328-c860-439d-bc84-4ddc03c14541"
      },
      "source": [
        "f1= f1_score(true_bools, pred_bools,average='micro')\n",
        "acc = accuracy_score(true_bools, pred_bools)\n",
        "\n",
        "print(f'F1-score (micro)  : {f1:.4f}')\n",
        "print(f'Accuracy (overall): {acc:.4f}')"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1-score (micro)  : 0.7005\n",
            "Accuracy (overall): 0.9185\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I5MkGJ1_5R0S"
      },
      "source": [
        "## Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yCYlBrdC5R3b",
        "outputId": "2006c5ec-8d2d-4d6f-a52c-f1594b56e48b"
      },
      "source": [
        "from sklearn.metrics import multilabel_confusion_matrix\n",
        "\n",
        "mcm = multilabel_confusion_matrix(true_bools, pred_bools)\n",
        "mcm"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[28619,   204],\n",
              "        [ 1115,  1977]],\n",
              "\n",
              "       [[31599,     3],\n",
              "        [  306,     7]],\n",
              "\n",
              "       [[30068,   180],\n",
              "        [  483,  1184]],\n",
              "\n",
              "       [[31816,     0],\n",
              "        [   99,     0]],\n",
              "\n",
              "       [[29977,   353],\n",
              "        [  568,  1017]],\n",
              "\n",
              "       [[31642,     4],\n",
              "        [  266,     3]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UQXeqLwS5R6q"
      },
      "source": [
        "## Classification Report"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3IeCxSiS5R9q",
        "outputId": "98e9a447-0295-449e-ee91-3f0d9f0a6c26"
      },
      "source": [
        "clf_report = classification_report(true_bools,pred_bools,\n",
        "                                   target_names=cols_label)\n",
        "\n",
        "print(clf_report)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "               precision    recall  f1-score   support\n",
            "\n",
            "        toxic       0.91      0.64      0.75      3092\n",
            " severe_toxic       0.70      0.02      0.04       313\n",
            "      obscene       0.87      0.71      0.78      1667\n",
            "       threat       0.00      0.00      0.00        99\n",
            "       insult       0.74      0.64      0.69      1585\n",
            "identity_hate       0.43      0.01      0.02       269\n",
            "\n",
            "    micro avg       0.85      0.60      0.70      7025\n",
            "    macro avg       0.61      0.34      0.38      7025\n",
            " weighted avg       0.82      0.60      0.67      7025\n",
            "  samples avg       0.06      0.05      0.05      7025\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NG-ozrEP5SAH"
      },
      "source": [
        "## Co-occurence Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yXL2f2zb5SEo"
      },
      "source": [
        "def get_df_coo(y_true,y_pred,column_names):\n",
        "    \"\"\"\n",
        "    Get Co-occurence matrix from test labels and predictions.\n",
        "    \"\"\"\n",
        "    yt = np.array(y_true,dtype=np.int32)\n",
        "    yp = np.array(y_pred,dtype=np.int32)\n",
        "    coo = yt.T.dot(yp)\n",
        "    df_coo = pd.DataFrame(coo, columns=column_names,index=column_names)\n",
        "    df_coo.loc['Total']= df_coo.sum(numeric_only=True, axis=0)\n",
        "    df_coo.loc[:,'Total'] = df_coo.sum(numeric_only=True, axis=1)\n",
        "    df_coo = df_coo.astype(np.int32)\n",
        "    return df_coo"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gds5a_GR5SHU"
      },
      "source": [
        "def highlight_diagf(dfx, color=\"khaki\"):\n",
        "    def highlight_diag(dfy):\n",
        "        a = np.full(dfy.shape, \"\", dtype=\"<U24\")\n",
        "        np.fill_diagonal(a, f\"background-color: {color}\")\n",
        "        df1 = pd.DataFrame(a, index=dfy.index, columns=dfy.columns)\n",
        "        return df1\n",
        "\n",
        "    return dfx.style.apply(highlight_diag, axis=None)"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "id": "q63tlAzX5SML",
        "outputId": "643bc8d0-1198-4a0c-ce6b-a2193aff9b6a"
      },
      "source": [
        "df_coo = get_df_coo(true_bools,pred_bools,column_names=cols_label)\n",
        "highlight_diagf(df_coo)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<style  type=\"text/css\" >\n",
              "#T_3a7e29ec_37e9_11eb_888f_0242ac1c0002row0_col0,#T_3a7e29ec_37e9_11eb_888f_0242ac1c0002row1_col1,#T_3a7e29ec_37e9_11eb_888f_0242ac1c0002row2_col2,#T_3a7e29ec_37e9_11eb_888f_0242ac1c0002row3_col3,#T_3a7e29ec_37e9_11eb_888f_0242ac1c0002row4_col4,#T_3a7e29ec_37e9_11eb_888f_0242ac1c0002row5_col5,#T_3a7e29ec_37e9_11eb_888f_0242ac1c0002row6_col6{\n",
              "            background-color:  khaki;\n",
              "        }</style><table id=\"T_3a7e29ec_37e9_11eb_888f_0242ac1c0002\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >toxic</th>        <th class=\"col_heading level0 col1\" >severe_toxic</th>        <th class=\"col_heading level0 col2\" >obscene</th>        <th class=\"col_heading level0 col3\" >threat</th>        <th class=\"col_heading level0 col4\" >insult</th>        <th class=\"col_heading level0 col5\" >identity_hate</th>        <th class=\"col_heading level0 col6\" >Total</th>    </tr></thead><tbody>\n",
              "                <tr>\n",
              "                        <th id=\"T_3a7e29ec_37e9_11eb_888f_0242ac1c0002level0_row0\" class=\"row_heading level0 row0\" >toxic</th>\n",
              "                        <td id=\"T_3a7e29ec_37e9_11eb_888f_0242ac1c0002row0_col0\" class=\"data row0 col0\" >1977</td>\n",
              "                        <td id=\"T_3a7e29ec_37e9_11eb_888f_0242ac1c0002row0_col1\" class=\"data row0 col1\" >10</td>\n",
              "                        <td id=\"T_3a7e29ec_37e9_11eb_888f_0242ac1c0002row0_col2\" class=\"data row0 col2\" >1313</td>\n",
              "                        <td id=\"T_3a7e29ec_37e9_11eb_888f_0242ac1c0002row0_col3\" class=\"data row0 col3\" >0</td>\n",
              "                        <td id=\"T_3a7e29ec_37e9_11eb_888f_0242ac1c0002row0_col4\" class=\"data row0 col4\" >1335</td>\n",
              "                        <td id=\"T_3a7e29ec_37e9_11eb_888f_0242ac1c0002row0_col5\" class=\"data row0 col5\" >7</td>\n",
              "                        <td id=\"T_3a7e29ec_37e9_11eb_888f_0242ac1c0002row0_col6\" class=\"data row0 col6\" >4642</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_3a7e29ec_37e9_11eb_888f_0242ac1c0002level0_row1\" class=\"row_heading level0 row1\" >severe_toxic</th>\n",
              "                        <td id=\"T_3a7e29ec_37e9_11eb_888f_0242ac1c0002row1_col0\" class=\"data row1 col0\" >309</td>\n",
              "                        <td id=\"T_3a7e29ec_37e9_11eb_888f_0242ac1c0002row1_col1\" class=\"data row1 col1\" >7</td>\n",
              "                        <td id=\"T_3a7e29ec_37e9_11eb_888f_0242ac1c0002row1_col2\" class=\"data row1 col2\" >288</td>\n",
              "                        <td id=\"T_3a7e29ec_37e9_11eb_888f_0242ac1c0002row1_col3\" class=\"data row1 col3\" >0</td>\n",
              "                        <td id=\"T_3a7e29ec_37e9_11eb_888f_0242ac1c0002row1_col4\" class=\"data row1 col4\" >297</td>\n",
              "                        <td id=\"T_3a7e29ec_37e9_11eb_888f_0242ac1c0002row1_col5\" class=\"data row1 col5\" >1</td>\n",
              "                        <td id=\"T_3a7e29ec_37e9_11eb_888f_0242ac1c0002row1_col6\" class=\"data row1 col6\" >902</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_3a7e29ec_37e9_11eb_888f_0242ac1c0002level0_row2\" class=\"row_heading level0 row2\" >obscene</th>\n",
              "                        <td id=\"T_3a7e29ec_37e9_11eb_888f_0242ac1c0002row2_col0\" class=\"data row2 col0\" >1457</td>\n",
              "                        <td id=\"T_3a7e29ec_37e9_11eb_888f_0242ac1c0002row2_col1\" class=\"data row2 col1\" >10</td>\n",
              "                        <td id=\"T_3a7e29ec_37e9_11eb_888f_0242ac1c0002row2_col2\" class=\"data row2 col2\" >1184</td>\n",
              "                        <td id=\"T_3a7e29ec_37e9_11eb_888f_0242ac1c0002row2_col3\" class=\"data row2 col3\" >0</td>\n",
              "                        <td id=\"T_3a7e29ec_37e9_11eb_888f_0242ac1c0002row2_col4\" class=\"data row2 col4\" >1163</td>\n",
              "                        <td id=\"T_3a7e29ec_37e9_11eb_888f_0242ac1c0002row2_col5\" class=\"data row2 col5\" >1</td>\n",
              "                        <td id=\"T_3a7e29ec_37e9_11eb_888f_0242ac1c0002row2_col6\" class=\"data row2 col6\" >3815</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_3a7e29ec_37e9_11eb_888f_0242ac1c0002level0_row3\" class=\"row_heading level0 row3\" >threat</th>\n",
              "                        <td id=\"T_3a7e29ec_37e9_11eb_888f_0242ac1c0002row3_col0\" class=\"data row3 col0\" >76</td>\n",
              "                        <td id=\"T_3a7e29ec_37e9_11eb_888f_0242ac1c0002row3_col1\" class=\"data row3 col1\" >0</td>\n",
              "                        <td id=\"T_3a7e29ec_37e9_11eb_888f_0242ac1c0002row3_col2\" class=\"data row3 col2\" >51</td>\n",
              "                        <td id=\"T_3a7e29ec_37e9_11eb_888f_0242ac1c0002row3_col3\" class=\"data row3 col3\" >0</td>\n",
              "                        <td id=\"T_3a7e29ec_37e9_11eb_888f_0242ac1c0002row3_col4\" class=\"data row3 col4\" >58</td>\n",
              "                        <td id=\"T_3a7e29ec_37e9_11eb_888f_0242ac1c0002row3_col5\" class=\"data row3 col5\" >0</td>\n",
              "                        <td id=\"T_3a7e29ec_37e9_11eb_888f_0242ac1c0002row3_col6\" class=\"data row3 col6\" >185</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_3a7e29ec_37e9_11eb_888f_0242ac1c0002level0_row4\" class=\"row_heading level0 row4\" >insult</th>\n",
              "                        <td id=\"T_3a7e29ec_37e9_11eb_888f_0242ac1c0002row4_col0\" class=\"data row4 col0\" >1316</td>\n",
              "                        <td id=\"T_3a7e29ec_37e9_11eb_888f_0242ac1c0002row4_col1\" class=\"data row4 col1\" >10</td>\n",
              "                        <td id=\"T_3a7e29ec_37e9_11eb_888f_0242ac1c0002row4_col2\" class=\"data row4 col2\" >964</td>\n",
              "                        <td id=\"T_3a7e29ec_37e9_11eb_888f_0242ac1c0002row4_col3\" class=\"data row4 col3\" >0</td>\n",
              "                        <td id=\"T_3a7e29ec_37e9_11eb_888f_0242ac1c0002row4_col4\" class=\"data row4 col4\" >1017</td>\n",
              "                        <td id=\"T_3a7e29ec_37e9_11eb_888f_0242ac1c0002row4_col5\" class=\"data row4 col5\" >0</td>\n",
              "                        <td id=\"T_3a7e29ec_37e9_11eb_888f_0242ac1c0002row4_col6\" class=\"data row4 col6\" >3307</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_3a7e29ec_37e9_11eb_888f_0242ac1c0002level0_row5\" class=\"row_heading level0 row5\" >identity_hate</th>\n",
              "                        <td id=\"T_3a7e29ec_37e9_11eb_888f_0242ac1c0002row5_col0\" class=\"data row5 col0\" >215</td>\n",
              "                        <td id=\"T_3a7e29ec_37e9_11eb_888f_0242ac1c0002row5_col1\" class=\"data row5 col1\" >1</td>\n",
              "                        <td id=\"T_3a7e29ec_37e9_11eb_888f_0242ac1c0002row5_col2\" class=\"data row5 col2\" >151</td>\n",
              "                        <td id=\"T_3a7e29ec_37e9_11eb_888f_0242ac1c0002row5_col3\" class=\"data row5 col3\" >0</td>\n",
              "                        <td id=\"T_3a7e29ec_37e9_11eb_888f_0242ac1c0002row5_col4\" class=\"data row5 col4\" >169</td>\n",
              "                        <td id=\"T_3a7e29ec_37e9_11eb_888f_0242ac1c0002row5_col5\" class=\"data row5 col5\" >3</td>\n",
              "                        <td id=\"T_3a7e29ec_37e9_11eb_888f_0242ac1c0002row5_col6\" class=\"data row5 col6\" >539</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_3a7e29ec_37e9_11eb_888f_0242ac1c0002level0_row6\" class=\"row_heading level0 row6\" >Total</th>\n",
              "                        <td id=\"T_3a7e29ec_37e9_11eb_888f_0242ac1c0002row6_col0\" class=\"data row6 col0\" >5350</td>\n",
              "                        <td id=\"T_3a7e29ec_37e9_11eb_888f_0242ac1c0002row6_col1\" class=\"data row6 col1\" >38</td>\n",
              "                        <td id=\"T_3a7e29ec_37e9_11eb_888f_0242ac1c0002row6_col2\" class=\"data row6 col2\" >3951</td>\n",
              "                        <td id=\"T_3a7e29ec_37e9_11eb_888f_0242ac1c0002row6_col3\" class=\"data row6 col3\" >0</td>\n",
              "                        <td id=\"T_3a7e29ec_37e9_11eb_888f_0242ac1c0002row6_col4\" class=\"data row6 col4\" >4039</td>\n",
              "                        <td id=\"T_3a7e29ec_37e9_11eb_888f_0242ac1c0002row6_col5\" class=\"data row6 col5\" >12</td>\n",
              "                        <td id=\"T_3a7e29ec_37e9_11eb_888f_0242ac1c0002row6_col6\" class=\"data row6 col6\" >13390</td>\n",
              "            </tr>\n",
              "    </tbody></table>"
            ],
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7f0cc4a33b70>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W70X5kIN5SP4"
      },
      "source": [
        "# Time Taken"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92j6ObHB5ST_",
        "outputId": "6a099948-4bd4-42fb-8767-36a76af5d181"
      },
      "source": [
        "time_taken = time.time() - time_start_notebook\n",
        "h,m = divmod(time_taken,60*60)\n",
        "print('Time taken to run whole notebook: {:.0f} hr '\\\n",
        "      '{:.0f} min {:.0f} secs'.format(h, *divmod(m,60)))\n",
        "\n",
        "# Time taken to run whole notebook: 1 hr 10 min 31 secs"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Time taken to run whole notebook: 0 hr 53 min 13 secs\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}