{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "y03_toxic_dl_bert_pytorch.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QbnHGRieZdk6"
      },
      "source": [
        "# Description\n",
        "In this project, we use the data from kaggle competition [Toxic Comment Classification Challenge by Jigsaw](https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/data?select=train.csv.zip) and only use the training data. Then we have break this raw training data into train and test data and evaluate the model performances in test data.\n",
        "\n",
        "The dataset is taken from wikipedia edit text and is classified as one of the following:\n",
        "\n",
        "1. toxic\n",
        "2. severe_toxic\n",
        "3. obscene\n",
        "4. threat\n",
        "5. insult\n",
        "6. identity_hate\n",
        "\n",
        "This is a multi-label (not-multiclass) classification. One text row has six labels and exactly one label is 1 and other labels are 0.\n",
        "\n",
        "\n",
        "References:\n",
        "- https://colab.research.google.com/github/rap12391/transformers_multilabel_toxic/blob/master/toxic_multilabel.ipynb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5tUoHe9FRhs"
      },
      "source": [
        "# Load the Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJpIjp6xaB13"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import time\n",
        "\n",
        "time_start_notebook = time.time()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dr7BCHS-nIRW",
        "scrolled": true
      },
      "source": [
        "%%capture\n",
        "import os\n",
        "import sys\n",
        "ENV_COLAB = 'google.colab' in sys.modules\n",
        "\n",
        "if ENV_COLAB:\n",
        "    ## install modules\n",
        "    !pip install transformers\n",
        "    !pip install scikit-plot\n",
        "    !pip install watermark\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hjaVhjaoaSIX",
        "outputId": "f8fe6fe9-47ed-4511-9510-7eeacd0f68fd"
      },
      "source": [
        "# data science\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "# visualization\n",
        "import seaborn as sns\n",
        "sns.set(color_codes=True)\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# mixed\n",
        "import os\n",
        "import time\n",
        "from pprint import pprint\n",
        "import joblib\n",
        "import pickle\n",
        "from tqdm import tqdm, trange\n",
        "from ast import literal_eval\n",
        "\n",
        "# random state\n",
        "SEED=100\n",
        "np.random.seed(SEED)\n",
        "\n",
        "# machine learning\n",
        "import sklearn\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix, multilabel_confusion_matrix\n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "\n",
        "# deep learning\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "import torch\n",
        "from torch.nn import BCEWithLogitsLoss, BCELoss\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from torch.utils.data import RandomSampler, SequentialSampler\n",
        "import transformers\n",
        "from transformers import *\n",
        "\n",
        "# model eval\n",
        "import scikitplot as skplt\n",
        "\n",
        "# versions\n",
        "import watermark\n",
        "%load_ext watermark\n",
        "%watermark -a \"Bhishan Poudel\" -d -v -m\n",
        "print()\n",
        "%watermark -iv"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Bhishan Poudel 2020-12-02 \n",
            "\n",
            "CPython 3.6.9\n",
            "IPython 5.5.0\n",
            "\n",
            "compiler   : GCC 8.4.0\n",
            "system     : Linux\n",
            "release    : 4.19.112+\n",
            "machine    : x86_64\n",
            "processor  : x86_64\n",
            "CPU cores  : 2\n",
            "interpreter: 64bit\n",
            "\n",
            "tensorflow              2.3.0\n",
            "transformers            4.0.0\n",
            "matplotlib              3.2.2\n",
            "transformers.file_utils 4.0.0\n",
            "torch                   1.7.0+cu101\n",
            "scikitplot              0.3.7\n",
            "watermark               2.0.2\n",
            "numpy                   1.18.5\n",
            "sklearn                 0.22.2.post1\n",
            "pandas                  1.1.4\n",
            "joblib                  0.17.0\n",
            "seaborn                 0.11.0\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v6otkefZbfcJ"
      },
      "source": [
        "# Useful Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x9QAg-Jpbfif"
      },
      "source": [
        "def show_methods(obj, ncols=4,contains=None):\n",
        "    lst = [i for i in dir(obj) if i[0]!='_' ]\n",
        "    if contains is not None:\n",
        "        lst = [i for i in lst if contains in i]\n",
        "    df = pd.DataFrame(np.array_split(lst,ncols)).T.fillna('')\n",
        "    return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xkHL76RubfnA"
      },
      "source": [
        "# GPU Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UhjnJEwKnISB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f9e2f3a-3a9f-47a8-d060-273edcc1ca8f"
      },
      "source": [
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uorMX_zrnISM",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c1bec028-ec45-4c21-8116-c60e9ad4906a"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "n_gpu = torch.cuda.device_count()\n",
        "torch.cuda.get_device_name(0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Tesla P100-PCIE-16GB'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dLcetMjZFjSH"
      },
      "source": [
        "## Load Training Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_YaKKtDR-WeQ"
      },
      "source": [
        "# %%capture\n",
        "# !wget https://github.com/bhishanpdl/Datasets/blob/master/Projects/Jigsaw_Toxic_Comment_Classification/train.csv.zip?raw=true\n",
        "# !unzip train.csv.zip?raw=true\n",
        "\n",
        "# !wget https://github.com/bhishanpdl/Datasets/blob/master/Projects/Jigsaw_Toxic_Comment_Classification/test.csv.zip?raw=true\n",
        "# !unzip test.csv.zip?raw=true"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EFMSmSgF-kFM",
        "outputId": "7145d731-8d8a-4222-ac97-017a345102ff"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " bert_model_toxic\t\t       test_data_loader\n",
            " classification_report_optimized.txt   train.csv\n",
            " classification_report.txt\t      'train.csv.zip?raw=true'\n",
            " comparisons.csv\t\t      'train.csv.zip?raw=true.1'\n",
            " sample_data\t\t\t       train_data_loader\n",
            " test.csv\t\t\t       validation_data_loader\n",
            "'test.csv.zip?raw=true'\t\t       valid_data_loader\n",
            "'test.csv.zip?raw=true.1'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ecREc7GnISW",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        },
        "outputId": "4000bbb0-72c0-424a-eb7a-69364fb1029a"
      },
      "source": [
        "df_train = pd.read_csv('train.csv')\n",
        "df_train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>comment_text</th>\n",
              "      <th>toxic</th>\n",
              "      <th>severe_toxic</th>\n",
              "      <th>obscene</th>\n",
              "      <th>threat</th>\n",
              "      <th>insult</th>\n",
              "      <th>identity_hate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>8d603d50affa1126</td>\n",
              "      <td>\"\\nYes, aside, thank you for trying to answer ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>8fb3576937b9e0d0</td>\n",
              "      <td>March 2010 (UTC)\\n\\nThanks! and understood abo...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>379440e04fb68e27</td>\n",
              "      <td>\"\\n\\n The Outfield \\n\\nHahaha - compassion is ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6be4446aac8ae028</td>\n",
              "      <td>Opposition is a source of strength. I believe ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1a2ff7ed958506a3</td>\n",
              "      <td>Please discontinue making those unsupported ch...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 id  ... identity_hate\n",
              "0  8d603d50affa1126  ...             0\n",
              "1  8fb3576937b9e0d0  ...             0\n",
              "2  379440e04fb68e27  ...             0\n",
              "3  6be4446aac8ae028  ...             0\n",
              "4  1a2ff7ed958506a3  ...             0\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6AhWrzX7nITB"
      },
      "source": [
        "col_text = 'comment_text'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MGF9lTdlcTkw",
        "outputId": "9349b6f9-78f8-498a-a896-d84e94d04acf"
      },
      "source": [
        "# unique text\n",
        "df_train[col_text].nunique(), df_train.shape[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(127656, 127656)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XgtwZwR-cib-",
        "outputId": "59191d24-0699-49f4-95d7-df6a71f8aaa2"
      },
      "source": [
        "# null values\n",
        "df_train.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id               0\n",
              "comment_text     0\n",
              "toxic            0\n",
              "severe_toxic     0\n",
              "obscene          0\n",
              "threat           0\n",
              "insult           0\n",
              "identity_hate    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UVI59S9VaAfB"
      },
      "source": [
        "cols_label = ['toxic', 'severe_toxic', 'obscene',\n",
        "              'threat', 'insult', 'identity_hate']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xzgA5qQgYIBZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "332bc353-c06f-454e-e180-11d9479276ab"
      },
      "source": [
        "print('Count of 1 per label: \\n', df_train[cols_label].sum(), '\\n') \n",
        "print('Count of 0 per label: \\n', df_train[cols_label].eq(0).sum())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Count of 1 per label: \n",
            " toxic            12202\n",
            "severe_toxic      1282\n",
            "obscene           6782\n",
            "threat             379\n",
            "insult            6292\n",
            "identity_hate     1136\n",
            "dtype: int64 \n",
            "\n",
            "Count of 0 per label: \n",
            " toxic            115454\n",
            "severe_toxic     126374\n",
            "obscene          120874\n",
            "threat           127277\n",
            "insult           121364\n",
            "identity_hate    126520\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "id": "HS7lsVmmi8S0",
        "outputId": "eb9aaf74-872f-4fb6-ec89-032bcb74aaec"
      },
      "source": [
        "df_train[cols_label].sum().plot.bar(title='Count of 1s',color='tomato');"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "id": "mXEosiFKjR0G",
        "outputId": "1304ba0c-47ef-486e-9ee7-985facd2b2b8"
      },
      "source": [
        "df_train[cols_label].eq(0).sum().plot.bar(title='Count of 0s');"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Dn9H1DFkDla"
      },
      "source": [
        "# Data Processing: Training Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JqCG-E7Kkr-S"
      },
      "source": [
        "## Shuffle and create ohe column"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFpSd4JzaAae"
      },
      "source": [
        "# shuffle data\n",
        "df_train = df_train.sample(frac=1,random_state=SEED).reset_index(drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0DF3ddjej5vd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "outputId": "f63cf5a3-0b2a-4c3b-aaca-4f618e6b6c26"
      },
      "source": [
        "col_ohe = 'one_hot_labels'\n",
        "df_train[col_ohe] = df_train[cols_label].to_numpy().tolist()\n",
        "df_train.head(2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>comment_text</th>\n",
              "      <th>toxic</th>\n",
              "      <th>severe_toxic</th>\n",
              "      <th>obscene</th>\n",
              "      <th>threat</th>\n",
              "      <th>insult</th>\n",
              "      <th>identity_hate</th>\n",
              "      <th>one_hot_labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>815dac68f62b1e6a</td>\n",
              "      <td>\"\\n\\n Defenestration \\n\\nIt was previously rep...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>570a66d523877761</td>\n",
              "      <td>I am easily able to trace my lineage back to C...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 id  ...      one_hot_labels\n",
              "0  815dac68f62b1e6a  ...  [0, 0, 0, 0, 0, 0]\n",
              "1  570a66d523877761  ...  [0, 0, 0, 0, 0, 0]\n",
              "\n",
              "[2 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MlhHifh5bW7e"
      },
      "source": [
        "labels    = list(df_train[col_ohe].values)\n",
        "list_text = list(df_train[col_text].values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gYd7ZcuUwhWB"
      },
      "source": [
        "# list_text[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-3zZRwCkwbO"
      },
      "source": [
        "## Load pretrained tokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IlMHfElhGJzc"
      },
      "source": [
        "Transformers pretrained tokenizers\n",
        "\n",
        "```python\n",
        "BERT:\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True) \n",
        "\n",
        "XLNet:\n",
        "tokenizer = XLNetTokenizer.from_pretrained('xlnet-base-cased', do_lower_case=False) \n",
        "\n",
        "RoBERTa:\n",
        "tokenizer = RobertaTokenizer.from_pretrained('roberta-base', do_lower_case=False)\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1qfxPObrlHYz"
      },
      "source": [
        "# show_methods(transformers,3,contains='Tokenizer')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gKBi6dMNl9uc"
      },
      "source": [
        "tokenizer = transformers.BertTokenizer.from_pretrained(\n",
        "    'bert-base-uncased',do_lower_case=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X8l8gTelsa0Z"
      },
      "source": [
        "## Get Encodings from tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fRJqDpA_sWEd",
        "outputId": "92e7ba33-e1ba-459c-965d-2aeda92c2f1e"
      },
      "source": [
        "%%time\n",
        "max_length = 100 # choose about 100 for colab\n",
        "encodings = tokenizer.batch_encode_plus(list_text,\n",
        "                max_length=max_length,\n",
        "                pad_to_max_length=True)\n",
        "\n",
        "print('tokenizer outputs: ', encodings.keys())\n",
        " \n",
        "# dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])\n",
        "# Wall time: 3min 28s"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2142: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "tokenizer outputs:  dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])\n",
            "CPU times: user 3min 17s, sys: 468 ms, total: 3min 18s\n",
            "Wall time: 3min 18s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l6CCLSjfur-9"
      },
      "source": [
        "input_ids       = encodings['input_ids']\n",
        "token_type_ids  = encodings['token_type_ids']\n",
        "attention_masks = encodings['attention_mask']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z7IpRNiqsgs4"
      },
      "source": [
        "## Find unique ohe indices"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSOFbThlYcpb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b5ca5be-0185-4bb4-e523-df429471e069"
      },
      "source": [
        "# Identifying indices of 'one_hot_labels' entries that only occur once\n",
        "# This will allow us to stratify split our training data later\n",
        "\n",
        "label_counts = df_train[col_ohe].astype(str).value_counts()\n",
        "one_freq = label_counts[label_counts==1].keys()\n",
        "\n",
        "cond = df_train[col_ohe].astype(str).isin(one_freq)\n",
        "one_freq_idxs = df_train[cond].index\n",
        "one_freq_idxs = sorted(list(one_freq_idxs), reverse=True)\n",
        "\n",
        "print('df_train label indices with only one instance: ', one_freq_idxs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "df_train label indices with only one instance:  [113097, 57059, 7039]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQQ7CoOag_r7"
      },
      "source": [
        "# Gathering single instance inputs to force\n",
        "# into the training set after stratified split\n",
        "\n",
        "one_freq_input_ids       = [input_ids.pop(i)       for i in one_freq_idxs]\n",
        "one_freq_token_types     = [token_type_ids.pop(i)  for i in one_freq_idxs]\n",
        "one_freq_attention_masks = [attention_masks.pop(i) for i in one_freq_idxs]\n",
        "one_freq_labels          = [labels.pop(i)          for i in one_freq_idxs]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9PxAt48HRRj"
      },
      "source": [
        "# Get train validation tensors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WPFaq4ufnIT2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57cd3fa6-450e-486a-ad97-7dc146a95f5b"
      },
      "source": [
        "%%time\n",
        "\n",
        "# train valid split using stratify\n",
        "\n",
        "train_inputs, valid_inputs,\\\n",
        "train_labels, valid_labels,\\\n",
        "train_token_types, valid_token_types,\\\n",
        "train_masks, valid_masks\\\n",
        "  = train_test_split(input_ids, labels, token_type_ids,attention_masks,\n",
        "                    random_state=SEED,\n",
        "                    test_size=0.10,\n",
        "                    stratify = labels)\n",
        "\n",
        "# Add one frequency data to train data\n",
        "train_inputs.extend(one_freq_input_ids)\n",
        "train_labels.extend(one_freq_labels)\n",
        "train_masks.extend(one_freq_attention_masks)\n",
        "train_token_types.extend(one_freq_token_types)\n",
        "\n",
        "# Convert all of our data into torch tensors\n",
        "train_inputs      = torch.tensor(train_inputs)\n",
        "train_labels      = torch.tensor(train_labels)\n",
        "train_masks       = torch.tensor(train_masks)\n",
        "train_token_types = torch.tensor(train_token_types)\n",
        "\n",
        "valid_inputs      = torch.tensor(valid_inputs)\n",
        "valid_labels      = torch.tensor(valid_labels)\n",
        "valid_masks       = torch.tensor(valid_masks)\n",
        "valid_token_types = torch.tensor(valid_token_types)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 3.2 s, sys: 115 ms, total: 3.32 s\n",
            "Wall time: 3.32 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-vexUChKsrC2"
      },
      "source": [
        "## Create DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QpqVVU8wtZ5C"
      },
      "source": [
        "from torch.utils.data import (TensorDataset, DataLoader,\n",
        "                              RandomSampler, SequentialSampler)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZRnuLna-nIT4"
      },
      "source": [
        "# Select a batch size for training.\n",
        "# For fine-tuning with XLNet, the authors recommend\n",
        "# a batch size of 32, 48, or 128.\n",
        "# We will use 32 here to avoid memory issues.\n",
        "batch_size = 32\n",
        "\n",
        "\n",
        "# Create an iterator of our data with torch DataLoader.\n",
        "# This helps save on memory during training because, unlike a for loop, \n",
        "# with an iterator the entire dataset does not need to be loaded into memory\n",
        "\n",
        "train_data       = TensorDataset(train_inputs, train_masks,\n",
        "                                 train_labels, train_token_types)\n",
        "train_sampler    = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler,\n",
        "                              batch_size=batch_size)\n",
        "\n",
        "valid_data       = TensorDataset(valid_inputs, valid_masks,\n",
        "                                 valid_labels, valid_token_types)\n",
        "valid_sampler    = SequentialSampler(valid_data)\n",
        "valid_dataloader = DataLoader(valid_data, sampler=valid_sampler,\n",
        "                              batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iiFRnP_ZTBFa"
      },
      "source": [
        "# # save data loaders\n",
        "# torch.save(train_dataloader,'train_data_loader')\n",
        "# torch.save(valid_dataloader,'valid_data_loader')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GDxmwEVfvNUF",
        "outputId": "7fafc079-7569-4c56-9af9-50129da8051f"
      },
      "source": [
        "# !ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " bert_model_toxic\t\t       test_data_loader\n",
            " classification_report_optimized.txt   train.csv\n",
            " classification_report.txt\t      'train.csv.zip?raw=true'\n",
            " comparisons.csv\t\t      'train.csv.zip?raw=true.1'\n",
            " sample_data\t\t\t       train_data_loader\n",
            " test.csv\t\t\t       validation_data_loader\n",
            "'test.csv.zip?raw=true'\t\t       valid_data_loader\n",
            "'test.csv.zip?raw=true.1'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ncGteBuSFuZM"
      },
      "source": [
        "## Load the Model for Sequence Classification\n",
        "\n",
        "```python\n",
        "BERT:\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True) \n",
        "\n",
        "XLNet:\n",
        "tokenizer = XLNetTokenizer.from_pretrained('xlnet-base-cased', do_lower_case=False) \n",
        "\n",
        "RoBERTa:\n",
        "tokenizer = RobertaTokenizer.from_pretrained('roberta-base', do_lower_case=False)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1j6aQDsxxYWh"
      },
      "source": [
        "# show_methods(transformers,contains='SequenceClassification',ncols=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ujk4k16DnIT6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12b31037-0a20-44f8-825a-eb01d88a4a1b"
      },
      "source": [
        "%%time\n",
        "# Load classification model\n",
        "\n",
        "num_labels = len(cols_label)\n",
        "model = transformers.BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\", num_labels=num_labels)\n",
        "model.cuda()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 6.38 s, sys: 1.37 s, total: 7.76 s\n",
            "Wall time: 8.27 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jGE4gv9qfhRG"
      },
      "source": [
        "## Choose Optimizer\n",
        "\n",
        "Setting custom optimization parameters for the AdamW optimizer https://huggingface.co/transformers/main_classes/optimizer_schedules.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "eydfC6i109pO",
        "outputId": "6a6347e4-c4f7-4e0b-f9fd-1697e8985ffa"
      },
      "source": [
        "show_methods(transformers,3,contains='Adam')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>AdamW</td>\n",
              "      <td>AdamWeightDecay</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       0                1 2\n",
              "0  AdamW  AdamWeightDecay  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GsV8zwWYnIT9"
      },
      "source": [
        "# setting custom optimization parameters.\n",
        "params_opt = list(model.named_parameters())\n",
        "\n",
        "no_decay = ['bias', 'gamma', 'beta']\n",
        "\n",
        "\n",
        "params_opt_group = [\n",
        "    # non decay params\n",
        "    {'params': [p for n, p in params_opt\n",
        "                if not any(nd in n for nd in no_decay)],\n",
        "     'weight_decay_rate': 0.01},\n",
        "\n",
        "    # decay params\n",
        "    {'params': [p for n, p in params_opt\n",
        "                if any(nd in n for nd in no_decay)],\n",
        "     'weight_decay_rate': 0.0}\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aOomZIEIoHOL"
      },
      "source": [
        "optimizer = transformers.AdamW(params_opt_group,lr=2e-5,correct_bias=True)\n",
        "# optimizer = AdamW(model.parameters(),lr=2e-5)  # Default optimization"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JRQQZ8zIFzLW"
      },
      "source": [
        "## Train Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uDLZmEC_oKo3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08e2795b-87de-4c25-d4ce-014a34c48c73"
      },
      "source": [
        "%%time\n",
        "\n",
        "from tqdm import trange\n",
        "\n",
        "# Store our loss and accuracy for plotting\n",
        "train_loss_set = []\n",
        "\n",
        "# Number of training epochs (authors recommend between 2 and 4)\n",
        "epochs = 3\n",
        "\n",
        "# trange is a tqdm wrapper around the normal python range\n",
        "for _ in trange(epochs, desc=\"Epoch\"):\n",
        "\n",
        "  # Training\n",
        "  \n",
        "  # train model\n",
        "  model.train()\n",
        "\n",
        "  # Tracking variables\n",
        "  tr_loss = 0\n",
        "  nb_tr_examples, nb_tr_steps = 0, 0\n",
        "  \n",
        "  # Train the data for one epoch\n",
        "  for step, batch in enumerate(train_dataloader):\n",
        "    # Add batch to GPU\n",
        "    batch = tuple(b.to(device) for b in batch)\n",
        "\n",
        "    # Unpack the inputs from our dataloader\n",
        "    b_input_ids, b_input_mask, b_labels, b_token_types = batch\n",
        "\n",
        "    # Clear out the gradients (by default they accumulate)\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # # Forward pass for multiclass classification\n",
        "    # outputs = model(b_input_ids, token_type_ids=None,\n",
        "    #                  attention_mask=b_input_mask, labels=b_labels)\n",
        "    # loss = outputs[0]\n",
        "    # logits = outputs[1]\n",
        "\n",
        "    # Forward pass for multilabel classification\n",
        "    outputs = model(b_input_ids, token_type_ids=None,\n",
        "                    attention_mask=b_input_mask)\n",
        "    logits = outputs[0]\n",
        "    loss_func = BCEWithLogitsLoss() \n",
        "    loss = loss_func(logits.view(-1,num_labels),\n",
        "                     b_labels.type_as(logits).view(-1,num_labels))\n",
        "    # loss_func = BCELoss() \n",
        "    # loss = loss_func(torch.sigmoid(logits.view(-1,num_labels)),\n",
        "    #             b_labels.type_as(logits).view(-1,num_labels))\n",
        "    train_loss_set.append(loss.item())    \n",
        "\n",
        "    # Backward pass\n",
        "    loss.backward()\n",
        "\n",
        "    # Update parameters and take a step using the computed gradient\n",
        "    optimizer.step()\n",
        "    # scheduler.step()\n",
        "\n",
        "    # Update tracking variables\n",
        "    tr_loss += loss.item()\n",
        "    nb_tr_examples += b_input_ids.size(0)\n",
        "    nb_tr_steps += 1\n",
        "\n",
        "  print(\"Train loss: {}\".format(tr_loss/nb_tr_steps))\n",
        "\n",
        "###############################################################################\n",
        "\n",
        "  # Validation\n",
        "\n",
        "  # Put model in evaluation mode to evaluate loss on the validation set\n",
        "  model.eval()\n",
        "\n",
        "  # Variables to gather full output\n",
        "  logit_preds,true_labels,pred_labels,tokenized_texts = [],[],[],[]\n",
        "\n",
        "  # Predict\n",
        "  for i, batch in enumerate(valid_dataloader):\n",
        "    batch = tuple(b.to(device) for b in batch)\n",
        "\n",
        "    # Unpack the inputs from our dataloader\n",
        "    b_input_ids, b_input_mask, b_labels, b_token_types = batch\n",
        "\n",
        "    with torch.no_grad():\n",
        "      # Forward pass\n",
        "      outs = model(b_input_ids, token_type_ids=None,\n",
        "                   attention_mask=b_input_mask)\n",
        "      b_logit_pred = outs[0]\n",
        "      pred_label = torch.sigmoid(b_logit_pred)\n",
        "\n",
        "      b_logit_pred = b_logit_pred.detach().cpu().numpy()\n",
        "      pred_label = pred_label.to('cpu').numpy()\n",
        "      b_labels = b_labels.to('cpu').numpy()\n",
        "\n",
        "    tokenized_texts.append(b_input_ids)\n",
        "    logit_preds.append(b_logit_pred)\n",
        "    true_labels.append(b_labels)\n",
        "    pred_labels.append(pred_label)\n",
        "\n",
        "  # Flatten outputs\n",
        "  pred_labels = [item for sublist in pred_labels for item in sublist]\n",
        "  true_labels = [item for sublist in true_labels for item in sublist]\n",
        "\n",
        "  # Calculate Accuracy\n",
        "  threshold = 0.50\n",
        "  pred_bools = [pl>threshold for pl in pred_labels]\n",
        "  true_bools = [tl==1 for tl in true_labels]\n",
        "  val_f1_accuracy = f1_score(true_bools,pred_bools,average='micro')*100\n",
        "  val_flat_accuracy = accuracy_score(true_bools, pred_bools)*100\n",
        "\n",
        "  print('F1 Validation Accuracy: ', val_f1_accuracy)\n",
        "  print('Flat Validation Accuracy: ', val_flat_accuracy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:   0%|          | 0/3 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss: 0.05367283841109552\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  33%|      | 1/3 [19:58<39:57, 1198.80s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "F1 Validation Accuracy:  79.13170375775266\n",
            "Flat Validation Accuracy:  92.95785680714398\n",
            "Train loss: 0.03492113039635946\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  67%|   | 2/3 [39:52<19:57, 1197.31s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "F1 Validation Accuracy:  79.21217547000894\n",
            "Flat Validation Accuracy:  93.07535641547861\n",
            "Train loss: 0.027673481150811315\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 100%|| 3/3 [59:44<00:00, 1194.76s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "F1 Validation Accuracy:  78.94641235240691\n",
            "Flat Validation Accuracy:  92.9735234215886\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aiBeiBSRoOuz"
      },
      "source": [
        "#  torch.save(model.state_dict(), 'bert_model_toxic')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_7dd2GE3F4yK"
      },
      "source": [
        "## Load and Preprocess Test Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y3R3ucxTM1vF",
        "outputId": "e6176f0f-a541-4cec-855f-ff74c4001d42"
      },
      "source": [
        "cols_label"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G5Q7hC4GFOLJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        },
        "outputId": "a436cd1a-e3cf-403c-b828-914f56525a61"
      },
      "source": [
        "df_test = pd.read_csv('test.csv')\n",
        "df_test.head(2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>comment_text</th>\n",
              "      <th>toxic</th>\n",
              "      <th>severe_toxic</th>\n",
              "      <th>obscene</th>\n",
              "      <th>threat</th>\n",
              "      <th>insult</th>\n",
              "      <th>identity_hate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>70bbc3e96dd459b1</td>\n",
              "      <td>Hammed it is, cheers!</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0b2e86f819b4b9a4</td>\n",
              "      <td>Not a problem, sorry for the inconvenience and...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 id  ... identity_hate\n",
              "0  70bbc3e96dd459b1  ...             0\n",
              "1  0b2e86f819b4b9a4  ...             0\n",
              "\n",
              "[2 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gx3U2yrSQzh4",
        "outputId": "bee0d905-1418-4d1a-e0e9-a853f4753a58"
      },
      "source": [
        "print('Count of 1 per label: \\n', df_test[cols_label].sum(), '\\n') \n",
        "print('Count of 0 per label: \\n', df_test[cols_label].eq(0).sum())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Count of 1 per label: \n",
            " toxic            3092\n",
            "severe_toxic      313\n",
            "obscene          1667\n",
            "threat             99\n",
            "insult           1585\n",
            "identity_hate     269\n",
            "dtype: int64 \n",
            "\n",
            "Count of 0 per label: \n",
            " toxic            28823\n",
            "severe_toxic     31602\n",
            "obscene          30248\n",
            "threat           31816\n",
            "insult           30330\n",
            "identity_hate    31646\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C-o4YlLlNnxl",
        "outputId": "5df31649-f55f-4136-fb3c-0cd378bd8fb6"
      },
      "source": [
        "# df_test_labels = pd.read_csv('test_labels.csv')\n",
        "# df_test = df_test.merge(df_test_labels, on='id', how='left')\n",
        "\n",
        "df_test.isna().sum().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        },
        "id": "LADneCcmQ9iC",
        "outputId": "9f2a7571-22dc-4b60-edbc-2c817fe03aa2"
      },
      "source": [
        "df_test[col_ohe] = df_test[cols_label].to_numpy().tolist()\n",
        "df_test.head(2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>comment_text</th>\n",
              "      <th>toxic</th>\n",
              "      <th>severe_toxic</th>\n",
              "      <th>obscene</th>\n",
              "      <th>threat</th>\n",
              "      <th>insult</th>\n",
              "      <th>identity_hate</th>\n",
              "      <th>one_hot_labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>70bbc3e96dd459b1</td>\n",
              "      <td>Hammed it is, cheers!</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0b2e86f819b4b9a4</td>\n",
              "      <td>Not a problem, sorry for the inconvenience and...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 id  ...      one_hot_labels\n",
              "0  70bbc3e96dd459b1  ...  [0, 0, 0, 0, 0, 0]\n",
              "1  0b2e86f819b4b9a4  ...  [0, 0, 0, 0, 0, 0]\n",
              "\n",
              "[2 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1a41OmU2i7qp"
      },
      "source": [
        "# Gathering input data\n",
        "test_labels   = list(df_test[cols_label].values)\n",
        "test_comments = list(df_test[col_text].values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2RJ6R2cZRp6V"
      },
      "source": [
        "## Tokenize Test Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "amySMO8EQzf2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a862c7f7-d7b7-472f-b81e-6d272cf79bda"
      },
      "source": [
        "%%time\n",
        "# Encoding input data\n",
        "test_encodings       = tokenizer.batch_encode_plus(test_comments,\n",
        "                                max_length=max_length,\n",
        "                                pad_to_max_length=True)\n",
        "test_input_ids       = test_encodings['input_ids']\n",
        "test_token_type_ids  = test_encodings['token_type_ids']\n",
        "test_attention_masks = test_encodings['attention_mask']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2142: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 46.7 s, sys: 41.7 ms, total: 46.7 s\n",
            "Wall time: 46.7 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZP80fjYNSFQ9"
      },
      "source": [
        "## Create Tensors for Test Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hqOfi9fkRaRN"
      },
      "source": [
        "# Make tensors out of data\n",
        "test_inputs      = torch.tensor(test_input_ids)\n",
        "test_labels      = torch.tensor(test_labels)\n",
        "test_masks       = torch.tensor(test_attention_masks)\n",
        "test_token_types = torch.tensor(test_token_type_ids)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uex-KuH1SVh1"
      },
      "source": [
        "## Create DataLoader for Test Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dWGXKJB9SS2O"
      },
      "source": [
        "# Create test dataloader\n",
        "test_data       = TensorDataset(test_inputs, test_masks, test_labels,\n",
        "                                test_token_types)\n",
        "test_sampler    = SequentialSampler(test_data)\n",
        "test_dataloader = DataLoader(test_data, sampler=test_sampler,\n",
        "                             batch_size=batch_size)\n",
        "\n",
        "# Save test dataloader\n",
        "torch.save(test_dataloader,'test_data_loader')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PFTWxCA_GBau"
      },
      "source": [
        "## Get the Predictions from Test Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NPvrL6OFSQvf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f57fb4c5-ee05-45fc-a4f1-8f5df28aa483"
      },
      "source": [
        "%%time\n",
        "# Test\n",
        "\n",
        "# Put model in evaluation mode to evaluate loss on the validation set\n",
        "model.eval()\n",
        "\n",
        "#track variables\n",
        "logit_preds,true_labels,pred_labels,tokenized_texts = [],[],[],[]\n",
        "\n",
        "# Predict\n",
        "for i, batch in enumerate(test_dataloader):\n",
        "  batch = tuple(b.to(device) for b in batch)\n",
        "\n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids, b_input_mask, b_labels, b_token_types = batch\n",
        "\n",
        "  with torch.no_grad():\n",
        "    # Forward pass\n",
        "    outs         = model(b_input_ids, token_type_ids=None,\n",
        "                         attention_mask=b_input_mask)\n",
        "    b_logit_pred = outs[0]\n",
        "    pred_label   = torch.sigmoid(b_logit_pred)\n",
        "\n",
        "    b_logit_pred = b_logit_pred.detach().cpu().numpy()\n",
        "    pred_label   = pred_label.to('cpu').numpy()\n",
        "    b_labels     = b_labels.to('cpu').numpy()\n",
        "\n",
        "  tokenized_texts.append(b_input_ids)\n",
        "  logit_preds.append(b_logit_pred)\n",
        "  true_labels.append(b_labels)\n",
        "  pred_labels.append(pred_label)\n",
        "\n",
        "# Flatten outputs\n",
        "tokenized_texts = [item  for sublist in tokenized_texts for item in sublist]\n",
        "pred_labels     = [item  for sublist in pred_labels     for item in sublist]\n",
        "true_labels     = [item  for sublist in true_labels     for item in sublist]\n",
        "true_bools      = [tl==1 for tl      in true_labels]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 1min 4s, sys: 34.8 s, total: 1min 39s\n",
            "Wall time: 1min 39s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJJB6X4paLm3"
      },
      "source": [
        "# Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uaL7HaIpXkZo",
        "outputId": "af92bdbf-b55c-40bc-9265-e96a594ab6f0"
      },
      "source": [
        "len(true_bools), df_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(31915, (31915, 9))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eWoIjgmxTnzc"
      },
      "source": [
        "pred_bools = [pl>0.50 for pl in pred_labels]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QeRDCZXFTxrv",
        "outputId": "96621d0a-88d2-486b-8be8-deecf70bc6c0"
      },
      "source": [
        "f1= f1_score(true_bools, pred_bools,average='micro')\n",
        "acc = accuracy_score(true_bools, pred_bools)\n",
        "\n",
        "print(f'F1-score (micro)  : {f1:.4f}')\n",
        "print(f'Accuracy (overall): {acc:.4f}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1-score (micro)  : 0.7796\n",
            "Accuracy (overall): 0.9251\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_AX9X2ATdgQ"
      },
      "source": [
        "## Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BE23bap4Xkhg",
        "outputId": "10e7536e-0a03-43b5-edc1-28a1f5be8bd4"
      },
      "source": [
        "from sklearn.metrics import multilabel_confusion_matrix\n",
        "\n",
        "mcm = multilabel_confusion_matrix(true_bools, pred_bools)\n",
        "mcm"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[28431,   392],\n",
              "        [  688,  2404]],\n",
              "\n",
              "       [[31482,   120],\n",
              "        [  179,   134]],\n",
              "\n",
              "       [[29948,   300],\n",
              "        [  274,  1393]],\n",
              "\n",
              "       [[31767,    49],\n",
              "        [   48,    51]],\n",
              "\n",
              "       [[29882,   448],\n",
              "        [  322,  1263]],\n",
              "\n",
              "       [[31582,    64],\n",
              "        [  149,   120]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQeGWqeMzAoZ"
      },
      "source": [
        "## Classification Report"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZcZUcYOxxmM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "324a85ae-fe17-4042-d129-9e301ea8c832"
      },
      "source": [
        "clf_report = classification_report(true_bools,pred_bools,\n",
        "                                   target_names=cols_label)\n",
        "\n",
        "print(clf_report)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "               precision    recall  f1-score   support\n",
            "\n",
            "        toxic       0.86      0.78      0.82      3092\n",
            " severe_toxic       0.53      0.43      0.47       313\n",
            "      obscene       0.82      0.84      0.83      1667\n",
            "       threat       0.51      0.52      0.51        99\n",
            "       insult       0.74      0.80      0.77      1585\n",
            "identity_hate       0.65      0.45      0.53       269\n",
            "\n",
            "    micro avg       0.80      0.76      0.78      7025\n",
            "    macro avg       0.69      0.63      0.65      7025\n",
            " weighted avg       0.80      0.76      0.78      7025\n",
            "  samples avg       0.07      0.07      0.07      7025\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wm-pv1x2frdu"
      },
      "source": [
        "## Co-occurence Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "id": "2HXZ3QwIfuec",
        "outputId": "83321c4c-df03-4709-e84c-cddbce918864"
      },
      "source": [
        "coo = np.array(true_bools,dtype=np.int16).T.dot(np.array(pred_bools,dtype=np.int16))\n",
        "df_coo = pd.DataFrame(coo, columns=cols_label,index=cols_label)\n",
        "df_coo.style.background_gradient()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<style  type=\"text/css\" >\n",
              "#T_8bbff4ee_34f0_11eb_a6d6_0242ac1c0002row0_col0,#T_8bbff4ee_34f0_11eb_a6d6_0242ac1c0002row0_col1,#T_8bbff4ee_34f0_11eb_a6d6_0242ac1c0002row0_col2,#T_8bbff4ee_34f0_11eb_a6d6_0242ac1c0002row0_col3,#T_8bbff4ee_34f0_11eb_a6d6_0242ac1c0002row0_col4,#T_8bbff4ee_34f0_11eb_a6d6_0242ac1c0002row0_col5{\n",
              "            background-color:  #023858;\n",
              "            color:  #f1f1f1;\n",
              "        }#T_8bbff4ee_34f0_11eb_a6d6_0242ac1c0002row1_col0{\n",
              "            background-color:  #f1ebf4;\n",
              "            color:  #000000;\n",
              "        }#T_8bbff4ee_34f0_11eb_a6d6_0242ac1c0002row1_col1{\n",
              "            background-color:  #7dacd1;\n",
              "            color:  #000000;\n",
              "        }#T_8bbff4ee_34f0_11eb_a6d6_0242ac1c0002row1_col2{\n",
              "            background-color:  #e5e1ef;\n",
              "            color:  #000000;\n",
              "        }#T_8bbff4ee_34f0_11eb_a6d6_0242ac1c0002row1_col3{\n",
              "            background-color:  #e1dfed;\n",
              "            color:  #000000;\n",
              "        }#T_8bbff4ee_34f0_11eb_a6d6_0242ac1c0002row1_col4{\n",
              "            background-color:  #e7e3f0;\n",
              "            color:  #000000;\n",
              "        }#T_8bbff4ee_34f0_11eb_a6d6_0242ac1c0002row1_col5{\n",
              "            background-color:  #d2d3e7;\n",
              "            color:  #000000;\n",
              "        }#T_8bbff4ee_34f0_11eb_a6d6_0242ac1c0002row2_col0{\n",
              "            background-color:  #348ebf;\n",
              "            color:  #000000;\n",
              "        }#T_8bbff4ee_34f0_11eb_a6d6_0242ac1c0002row2_col1{\n",
              "            background-color:  #023b5d;\n",
              "            color:  #f1f1f1;\n",
              "        }#T_8bbff4ee_34f0_11eb_a6d6_0242ac1c0002row2_col2{\n",
              "            background-color:  #045b8f;\n",
              "            color:  #f1f1f1;\n",
              "        }#T_8bbff4ee_34f0_11eb_a6d6_0242ac1c0002row2_col3,#T_8bbff4ee_34f0_11eb_a6d6_0242ac1c0002row4_col3{\n",
              "            background-color:  #67a4cc;\n",
              "            color:  #000000;\n",
              "        }#T_8bbff4ee_34f0_11eb_a6d6_0242ac1c0002row2_col4{\n",
              "            background-color:  #0570b0;\n",
              "            color:  #f1f1f1;\n",
              "        }#T_8bbff4ee_34f0_11eb_a6d6_0242ac1c0002row2_col5{\n",
              "            background-color:  #056fae;\n",
              "            color:  #f1f1f1;\n",
              "        }#T_8bbff4ee_34f0_11eb_a6d6_0242ac1c0002row3_col0,#T_8bbff4ee_34f0_11eb_a6d6_0242ac1c0002row3_col1,#T_8bbff4ee_34f0_11eb_a6d6_0242ac1c0002row3_col2,#T_8bbff4ee_34f0_11eb_a6d6_0242ac1c0002row3_col4,#T_8bbff4ee_34f0_11eb_a6d6_0242ac1c0002row3_col5,#T_8bbff4ee_34f0_11eb_a6d6_0242ac1c0002row5_col3{\n",
              "            background-color:  #fff7fb;\n",
              "            color:  #000000;\n",
              "        }#T_8bbff4ee_34f0_11eb_a6d6_0242ac1c0002row3_col3{\n",
              "            background-color:  #a1bbda;\n",
              "            color:  #000000;\n",
              "        }#T_8bbff4ee_34f0_11eb_a6d6_0242ac1c0002row4_col0{\n",
              "            background-color:  #4496c3;\n",
              "            color:  #000000;\n",
              "        }#T_8bbff4ee_34f0_11eb_a6d6_0242ac1c0002row4_col1{\n",
              "            background-color:  #045585;\n",
              "            color:  #f1f1f1;\n",
              "        }#T_8bbff4ee_34f0_11eb_a6d6_0242ac1c0002row4_col2{\n",
              "            background-color:  #1b7eb7;\n",
              "            color:  #000000;\n",
              "        }#T_8bbff4ee_34f0_11eb_a6d6_0242ac1c0002row4_col4{\n",
              "            background-color:  #056dac;\n",
              "            color:  #f1f1f1;\n",
              "        }#T_8bbff4ee_34f0_11eb_a6d6_0242ac1c0002row4_col5{\n",
              "            background-color:  #0a73b2;\n",
              "            color:  #f1f1f1;\n",
              "        }#T_8bbff4ee_34f0_11eb_a6d6_0242ac1c0002row5_col0{\n",
              "            background-color:  #f6eff7;\n",
              "            color:  #000000;\n",
              "        }#T_8bbff4ee_34f0_11eb_a6d6_0242ac1c0002row5_col1{\n",
              "            background-color:  #e4e1ef;\n",
              "            color:  #000000;\n",
              "        }#T_8bbff4ee_34f0_11eb_a6d6_0242ac1c0002row5_col2{\n",
              "            background-color:  #f4eef6;\n",
              "            color:  #000000;\n",
              "        }#T_8bbff4ee_34f0_11eb_a6d6_0242ac1c0002row5_col4{\n",
              "            background-color:  #f2ecf5;\n",
              "            color:  #000000;\n",
              "        }#T_8bbff4ee_34f0_11eb_a6d6_0242ac1c0002row5_col5{\n",
              "            background-color:  #2d8abd;\n",
              "            color:  #000000;\n",
              "        }</style><table id=\"T_8bbff4ee_34f0_11eb_a6d6_0242ac1c0002\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >toxic</th>        <th class=\"col_heading level0 col1\" >severe_toxic</th>        <th class=\"col_heading level0 col2\" >obscene</th>        <th class=\"col_heading level0 col3\" >threat</th>        <th class=\"col_heading level0 col4\" >insult</th>        <th class=\"col_heading level0 col5\" >identity_hate</th>    </tr></thead><tbody>\n",
              "                <tr>\n",
              "                        <th id=\"T_8bbff4ee_34f0_11eb_a6d6_0242ac1c0002level0_row0\" class=\"row_heading level0 row0\" >toxic</th>\n",
              "                        <td id=\"T_8bbff4ee_34f0_11eb_a6d6_0242ac1c0002row0_col0\" class=\"data row0 col0\" >2411</td>\n",
              "                        <td id=\"T_8bbff4ee_34f0_11eb_a6d6_0242ac1c0002row0_col1\" class=\"data row0 col1\" >263</td>\n",
              "                        <td id=\"T_8bbff4ee_34f0_11eb_a6d6_0242ac1c0002row0_col2\" class=\"data row0 col2\" >1607</td>\n",
              "                        <td id=\"T_8bbff4ee_34f0_11eb_a6d6_0242ac1c0002row0_col3\" class=\"data row0 col3\" >101</td>\n",
              "                        <td id=\"T_8bbff4ee_34f0_11eb_a6d6_0242ac1c0002row0_col4\" class=\"data row0 col4\" >1638</td>\n",
              "                        <td id=\"T_8bbff4ee_34f0_11eb_a6d6_0242ac1c0002row0_col5\" class=\"data row0 col5\" >182</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_8bbff4ee_34f0_11eb_a6d6_0242ac1c0002level0_row1\" class=\"row_heading level0 row1\" >severe_toxic</th>\n",
              "                        <td id=\"T_8bbff4ee_34f0_11eb_a6d6_0242ac1c0002row1_col0\" class=\"data row1 col0\" >311</td>\n",
              "                        <td id=\"T_8bbff4ee_34f0_11eb_a6d6_0242ac1c0002row1_col1\" class=\"data row1 col1\" >137</td>\n",
              "                        <td id=\"T_8bbff4ee_34f0_11eb_a6d6_0242ac1c0002row1_col2\" class=\"data row1 col2\" >305</td>\n",
              "                        <td id=\"T_8bbff4ee_34f0_11eb_a6d6_0242ac1c0002row1_col3\" class=\"data row1 col3\" >35</td>\n",
              "                        <td id=\"T_8bbff4ee_34f0_11eb_a6d6_0242ac1c0002row1_col4\" class=\"data row1 col4\" >297</td>\n",
              "                        <td id=\"T_8bbff4ee_34f0_11eb_a6d6_0242ac1c0002row1_col5\" class=\"data row1 col5\" >49</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_8bbff4ee_34f0_11eb_a6d6_0242ac1c0002level0_row2\" class=\"row_heading level0 row2\" >obscene</th>\n",
              "                        <td id=\"T_8bbff4ee_34f0_11eb_a6d6_0242ac1c0002row2_col0\" class=\"data row2 col0\" >1559</td>\n",
              "                        <td id=\"T_8bbff4ee_34f0_11eb_a6d6_0242ac1c0002row2_col1\" class=\"data row2 col1\" >260</td>\n",
              "                        <td id=\"T_8bbff4ee_34f0_11eb_a6d6_0242ac1c0002row2_col2\" class=\"data row2 col2\" >1396</td>\n",
              "                        <td id=\"T_8bbff4ee_34f0_11eb_a6d6_0242ac1c0002row2_col3\" class=\"data row2 col3\" >63</td>\n",
              "                        <td id=\"T_8bbff4ee_34f0_11eb_a6d6_0242ac1c0002row2_col4\" class=\"data row2 col4\" >1243</td>\n",
              "                        <td id=\"T_8bbff4ee_34f0_11eb_a6d6_0242ac1c0002row2_col5\" class=\"data row2 col5\" >139</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_8bbff4ee_34f0_11eb_a6d6_0242ac1c0002level0_row3\" class=\"row_heading level0 row3\" >threat</th>\n",
              "                        <td id=\"T_8bbff4ee_34f0_11eb_a6d6_0242ac1c0002row3_col0\" class=\"data row3 col0\" >93</td>\n",
              "                        <td id=\"T_8bbff4ee_34f0_11eb_a6d6_0242ac1c0002row3_col1\" class=\"data row3 col1\" >22</td>\n",
              "                        <td id=\"T_8bbff4ee_34f0_11eb_a6d6_0242ac1c0002row3_col2\" class=\"data row3 col2\" >62</td>\n",
              "                        <td id=\"T_8bbff4ee_34f0_11eb_a6d6_0242ac1c0002row3_col3\" class=\"data row3 col3\" >52</td>\n",
              "                        <td id=\"T_8bbff4ee_34f0_11eb_a6d6_0242ac1c0002row3_col4\" class=\"data row3 col4\" >65</td>\n",
              "                        <td id=\"T_8bbff4ee_34f0_11eb_a6d6_0242ac1c0002row3_col5\" class=\"data row3 col5\" >7</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_8bbff4ee_34f0_11eb_a6d6_0242ac1c0002level0_row4\" class=\"row_heading level0 row4\" >insult</th>\n",
              "                        <td id=\"T_8bbff4ee_34f0_11eb_a6d6_0242ac1c0002row4_col0\" class=\"data row4 col0\" >1470</td>\n",
              "                        <td id=\"T_8bbff4ee_34f0_11eb_a6d6_0242ac1c0002row4_col1\" class=\"data row4 col1\" >237</td>\n",
              "                        <td id=\"T_8bbff4ee_34f0_11eb_a6d6_0242ac1c0002row4_col2\" class=\"data row4 col2\" >1134</td>\n",
              "                        <td id=\"T_8bbff4ee_34f0_11eb_a6d6_0242ac1c0002row4_col3\" class=\"data row4 col3\" >63</td>\n",
              "                        <td id=\"T_8bbff4ee_34f0_11eb_a6d6_0242ac1c0002row4_col4\" class=\"data row4 col4\" >1266</td>\n",
              "                        <td id=\"T_8bbff4ee_34f0_11eb_a6d6_0242ac1c0002row4_col5\" class=\"data row4 col5\" >136</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_8bbff4ee_34f0_11eb_a6d6_0242ac1c0002level0_row5\" class=\"row_heading level0 row5\" >identity_hate</th>\n",
              "                        <td id=\"T_8bbff4ee_34f0_11eb_a6d6_0242ac1c0002row5_col0\" class=\"data row5 col0\" >234</td>\n",
              "                        <td id=\"T_8bbff4ee_34f0_11eb_a6d6_0242ac1c0002row5_col1\" class=\"data row5 col1\" >61</td>\n",
              "                        <td id=\"T_8bbff4ee_34f0_11eb_a6d6_0242ac1c0002row5_col2\" class=\"data row5 col2\" >175</td>\n",
              "                        <td id=\"T_8bbff4ee_34f0_11eb_a6d6_0242ac1c0002row5_col3\" class=\"data row5 col3\" >21</td>\n",
              "                        <td id=\"T_8bbff4ee_34f0_11eb_a6d6_0242ac1c0002row5_col4\" class=\"data row5 col4\" >200</td>\n",
              "                        <td id=\"T_8bbff4ee_34f0_11eb_a6d6_0242ac1c0002row5_col5\" class=\"data row5 col5\" >120</td>\n",
              "            </tr>\n",
              "    </tbody></table>"
            ],
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7f7c78078438>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PWFd18u3zlF8"
      },
      "source": [
        "# Optimize Micro and Macro F-1 score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PHlhb2lvar8V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d5564f4-9117-4605-9665-d36fccc9d284"
      },
      "source": [
        " # Calculate Accuracy - maximize F1 accuracy by tuning threshold values.\n",
        "# First with 'macro_thresholds' on the order of e^-1\n",
        "# then with 'micro_thresholds' on the order of e^-2\n",
        "\n",
        "macro_thresholds = np.array(range(1,10))/10\n",
        "\n",
        "f1_results, flat_acc_results = [], []\n",
        "for th in macro_thresholds:\n",
        "  pred_bools = [pl>th for pl in pred_labels]\n",
        "  test_f1_accuracy   = f1_score(true_bools,pred_bools,average='micro')\n",
        "  test_flat_accuracy = accuracy_score(true_bools, pred_bools)\n",
        "  f1_results.append(test_f1_accuracy)\n",
        "  flat_acc_results.append(test_flat_accuracy)\n",
        "\n",
        "\n",
        "best_f1_idx     = np.argmax(f1_results) \n",
        "best_macro_th   = macro_thresholds[np.argmax(f1_results)]\n",
        "best_pred_bools = [pl>macro_thresholds[best_f1_idx] for pl in pred_labels]\n",
        "\n",
        "r = classification_report(true_bools,best_pred_bools,\n",
        "                            target_names=cols_label)\n",
        "\n",
        "print(f'Best Threshold     : {macro_thresholds[best_f1_idx]:}')\n",
        "print(f'Test F1 Accuracy   : {f1_results[best_f1_idx]:.4f}')\n",
        "print(f'Test Flat Accuracy : {flat_acc_results[best_f1_idx]:.4f}')\n",
        "print(r)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best Threshold     : 0.4\n",
            "Test F1 Accuracy   : 0.7802\n",
            "Test Flat Accuracy : 0.9232\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "        toxic       0.84      0.80      0.82      3092\n",
            " severe_toxic       0.48      0.56      0.52       313\n",
            "      obscene       0.79      0.86      0.83      1667\n",
            "       threat       0.49      0.56      0.52        99\n",
            "       insult       0.71      0.83      0.77      1585\n",
            "identity_hate       0.60      0.46      0.52       269\n",
            "\n",
            "    micro avg       0.76      0.80      0.78      7025\n",
            "    macro avg       0.65      0.68      0.66      7025\n",
            " weighted avg       0.77      0.80      0.78      7025\n",
            "  samples avg       0.07      0.07      0.07      7025\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wxk4RWjBVqUW",
        "outputId": "970e0766-dba6-4bc6-a225-2494f73872bb"
      },
      "source": [
        "# F1 micro thresholds\n",
        "micro_thresholds = (np.array(range(10))/100)+best_macro_th\n",
        "\n",
        "f1_results, flat_acc_results = [], []\n",
        "for th in micro_thresholds:\n",
        "  pred_bools = [pl>th for pl in pred_labels]\n",
        "  test_f1_accuracy = f1_score(true_bools,pred_bools,average='micro')\n",
        "  test_flat_accuracy = accuracy_score(true_bools, pred_bools)\n",
        "  f1_results.append(test_f1_accuracy)\n",
        "  flat_acc_results.append(test_flat_accuracy)\n",
        "\n",
        "best_f1_idx     = np.argmax(f1_results)\n",
        "best_pred_bools = [pl>micro_thresholds[best_f1_idx] for pl in pred_labels]\n",
        "r               = classification_report(true_bools,best_pred_bools,\n",
        "                                            target_names=cols_label)\n",
        "\n",
        "\n",
        "print(f'Best Threshold     : {micro_thresholds[best_f1_idx]:}')\n",
        "print(f'Test F1 Accuracy   : {f1_results[best_f1_idx]:.4f}')\n",
        "print(f'Test Flat Accuracy : {flat_acc_results[best_f1_idx]:.4f}')\n",
        "print(r)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best Threshold     : 0.41000000000000003\n",
            "Test F1 Accuracy   : 0.7806\n",
            "Test Flat Accuracy : 0.9234\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "        toxic       0.84      0.80      0.82      3092\n",
            " severe_toxic       0.48      0.56      0.52       313\n",
            "      obscene       0.80      0.86      0.83      1667\n",
            "       threat       0.50      0.56      0.52        99\n",
            "       insult       0.71      0.83      0.77      1585\n",
            "identity_hate       0.60      0.46      0.52       269\n",
            "\n",
            "    micro avg       0.77      0.79      0.78      7025\n",
            "    macro avg       0.66      0.68      0.66      7025\n",
            " weighted avg       0.77      0.79      0.78      7025\n",
            "  samples avg       0.07      0.07      0.07      7025\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oBg6UCYAYtIe"
      },
      "source": [
        "# Time Taken"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VGBSQZ7JYXhx",
        "outputId": "ddcd8b12-52b1-40e8-dfc8-1df6496bfac1"
      },
      "source": [
        "time_taken = time.time() - time_start_notebook\n",
        "h,m = divmod(time_taken,60*60)\n",
        "print('Time taken to run whole notebook: {:.0f} hr '\\\n",
        "      '{:.0f} min {:.0f} secs'.format(h, *divmod(m,60)))\n",
        "\n",
        "# Time taken to run whole notebook: 1 hr 10 min 31 secs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Time taken to run whole notebook: 1 hr 10 min 31 secs\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}